{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ada4ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Counter in c:\\users\\grace\\anaconda3\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c63d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora, models\n",
    "# from transformers import pipeline\n",
    "import string\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# import liwc\n",
    "import collections\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# from transformers import BertModel\n",
    "# from transformers import AutoTokenizer\n",
    "# from transformers import pipeline\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "save_progress = \"save_progress/\"\n",
    "data = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b186f6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\grace\\\\Desktop\\\\old_classes\\\\macs_404_patterns\\\\folktales\\\\utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfb752",
   "metadata": {},
   "source": [
    "# Processing story data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6ad5967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = pd.read_csv(data+'folk_tales_deduplicated.csv')\n",
    "stories = stories[['nation','title','text']]\n",
    "stories = stories.dropna(subset = ['nation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578202e",
   "metadata": {},
   "source": [
    "### Getting lemmas/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5bdb029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [utils.to_wordlist([stories.text[x]]) for x in stories.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "37da82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_bystory = []\n",
    "for story in wordlist:\n",
    "    wordlist_bystory.append([word for chunk in story for word in chunk])\n",
    "stories['wordlist'] = wordlist_bystory\n",
    "stories['cleaned'] = [\" \".join(stories.wordlist[i]).replace(\"-\",\" \") for i in stories.index]\n",
    "stories['cleaned'] = [re.sub('[^a-zA-Z ]','',x) for x in stories.cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "823b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stories.loc[stories['cleaned'].str.contains(' thor ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cafbd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas = stories['cleaned'].apply(utils.get_lemmas)\n",
    "# lemmas.to_pickle(save_progress+'story_lemmas.pkl')\n",
    "lemmas = pd.read_pickle(save_progress+'story_lemmas.pkl')\n",
    "# stories['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6ae27023",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrased = utils.make_bigrams(lemmas)\n",
    "stories['phrased'] = phrased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd75f18",
   "metadata": {},
   "source": [
    "### Getting language families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1ee1ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data+\"grouped_regions.json\") as f:\n",
    "    grouped_regions = json.load(f)\n",
    "\n",
    "lang_fam = []\n",
    "for i in stories.index:\n",
    "    hasfam = False\n",
    "    for key in grouped_regions.keys():\n",
    "        if stories.loc[i,'nation'] in grouped_regions[key]:\n",
    "            lang_fam.append(key)\n",
    "            hasfam = True\n",
    "    if not hasfam:\n",
    "        lang_fam.append(np.nan)\n",
    "stories['language_family'] = lang_fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03ff0e",
   "metadata": {},
   "source": [
    "### Saving/reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "64460b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories['sid'] = stories.index\n",
    "stories['sid'] = stories['sid'].apply(lambda x: 'sid'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6c918720",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.to_csv(save_progress+'stories.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39de3bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nation</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wordlist</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>phrased</th>\n",
       "      <th>language_family</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japanese</td>\n",
       "      <td>Momotaro</td>\n",
       "      <td>If you’ll believe me there was a time when the...</td>\n",
       "      <td>['believe', 'time', 'fairies', 'none', 'shy', ...</td>\n",
       "      <td>believe time fairies none shy time beasts talk...</td>\n",
       "      <td>['believe', 'time', 'fairy', 'none', 'time', '...</td>\n",
       "      <td>['believe', 'time', 'fairy', 'none', 'time', '...</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>sid0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serbian</td>\n",
       "      <td>The Birdcatcher</td>\n",
       "      <td>Near Constantinople there lived a man who knew...</td>\n",
       "      <td>['near', 'constantinople', 'lived', 'man', 'kn...</td>\n",
       "      <td>near constantinople lived man knew occupation ...</td>\n",
       "      <td>['near', 'constantinople', 'live', 'knew', 'oc...</td>\n",
       "      <td>['near', 'constantinople', 'live', 'knew', 'oc...</td>\n",
       "      <td>slavic</td>\n",
       "      <td>sid1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nation            title  \\\n",
       "0  japanese         Momotaro   \n",
       "1   serbian  The Birdcatcher   \n",
       "\n",
       "                                                text  \\\n",
       "0  If you’ll believe me there was a time when the...   \n",
       "1  Near Constantinople there lived a man who knew...   \n",
       "\n",
       "                                            wordlist  \\\n",
       "0  ['believe', 'time', 'fairies', 'none', 'shy', ...   \n",
       "1  ['near', 'constantinople', 'lived', 'man', 'kn...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  believe time fairies none shy time beasts talk...   \n",
       "1  near constantinople lived man knew occupation ...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  ['believe', 'time', 'fairy', 'none', 'time', '...   \n",
       "1  ['near', 'constantinople', 'live', 'knew', 'oc...   \n",
       "\n",
       "                                             phrased language_family   sid  \n",
       "0  ['believe', 'time', 'fairy', 'none', 'time', '...       east_asia  sid0  \n",
       "1  ['near', 'constantinople', 'live', 'knew', 'oc...          slavic  sid1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories = pd.read_csv(save_progress+'stories.csv')\n",
    "sid_nation = {}\n",
    "for i in stories.index:\n",
    "    sid_nation[stories['sid'][i]] = stories['nation'][i]\n",
    "nation_sid = {}\n",
    "for nation in stories.nation.unique():\n",
    "    nation_sid[nation] = list(stories.query('nation == @nation')['sid'])\n",
    "stories.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e41d0",
   "metadata": {},
   "source": [
    "## Processing Hofstede data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "20910d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hofstede = pd.read_excel(data+'hofstede.xlsx') # https://www.kaggle.com/datasets/aleksakenjic/hofstedes-cultural-dimensions\n",
    "language = pd.read_csv(data+'countries_languages.csv') # https://www.kaggle.com/datasets/shubhamptrivedi/languages-spoken-across-various-nations\n",
    "language['main'] = language['Languages Spoken'].apply(lambda x: x.split(' ')[0].replace(',','').split('/')[0])\n",
    "hofstede = pd.merge(hofstede,language[['Country','main']],how='left',left_on='country',right_on='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b37cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctr</th>\n",
       "      <th>country</th>\n",
       "      <th>pdi</th>\n",
       "      <th>idv</th>\n",
       "      <th>mas</th>\n",
       "      <th>uai</th>\n",
       "      <th>ltowvs</th>\n",
       "      <th>ivr</th>\n",
       "      <th>estim</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Country</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOS</td>\n",
       "      <td>Bosnia</td>\n",
       "      <td>90</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>87</td>\n",
       "      <td>69.773300</td>\n",
       "      <td>44.196429</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CZE</td>\n",
       "      <td>Czech Rep</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>70.025189</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DOM</td>\n",
       "      <td>Dominican Rep</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>13.098237</td>\n",
       "      <td>54.241071</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HOK</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>68</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>60.957179</td>\n",
       "      <td>16.964286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>KOR</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>85</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>MAC</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>90</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PUE</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.955357</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>STP</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SLK</td>\n",
       "      <td>Slovak Rep</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>51</td>\n",
       "      <td>76.574307</td>\n",
       "      <td>28.348214</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>USA</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>40</td>\n",
       "      <td>91</td>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>25.692695</td>\n",
       "      <td>68.080357</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ctr                country  pdi  idv  mas  uai      ltowvs        ivr  \\\n",
       "11  BOS                 Bosnia   90   22   48   87   69.773300  44.196429   \n",
       "21  CZE              Czech Rep   57   58   57   74   70.025189  29.464286   \n",
       "23  DOM          Dominican Rep   65   30   65   45   13.098237  54.241071   \n",
       "34  HOK              Hong Kong   68   25   57   29   60.957179  16.964286   \n",
       "46  KOR            South Korea   60   18   39   85  100.000000  29.464286   \n",
       "62  MAC        North Macedonia   90   22   45   87   62.000000  35.000000   \n",
       "70  PUE            Puerto Rico   68   27   56   38    0.000000  89.955357   \n",
       "73  STP  Sao Tome and Principe   75   37   24   70   32.000000  41.000000   \n",
       "77  SLK             Slovak Rep  100   52  110   51   76.574307  28.348214   \n",
       "89  USA                 U.S.A.   40   91   62   46   25.692695  68.080357   \n",
       "\n",
       "    estim  Unnamed: 9 Unnamed: 10 Country main  \n",
       "11      1         NaN         NaN     NaN  NaN  \n",
       "21      0         NaN         NaN     NaN  NaN  \n",
       "23      1         NaN         NaN     NaN  NaN  \n",
       "34      0         NaN         NaN     NaN  NaN  \n",
       "46      0         NaN         NaN     NaN  NaN  \n",
       "62      1         NaN         NaN     NaN  NaN  \n",
       "70      1         NaN         NaN     NaN  NaN  \n",
       "73      1         NaN         NaN     NaN  NaN  \n",
       "77      0         NaN         NaN     NaN  NaN  \n",
       "89      0         NaN         NaN     NaN  NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hofstede[hofstede['main'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "7d5ad6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hofstede_fillna = {'Bosnia':'bosnian','Czech Rep':'czechoslovak','South Korea':'korean','U.S.A':'English'}\n",
    "hofstede['main'] = hofstede['main'].apply(lambda x: hofstede_fillna[x] if x in hofstede_fillna.keys() else x)\n",
    "hofstede = hofstede.groupby('main').mean().reset_index()\n",
    "hofstede['main'] = hofstede['main'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "3d4f26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_hofstede = pd.merge(stories[['sid','nation','language_family','title','text']], hofstede[['pdi','idv','mas','uai','ltowvs','ivr','main']], left_on='nation', right_on='main', how='inner').drop(columns='main')\n",
    "stories_hofstede.to_csv(save_progress+'stories_hofstede.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b5f9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>nation</th>\n",
       "      <th>language_family</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>pdi</th>\n",
       "      <th>idv</th>\n",
       "      <th>mas</th>\n",
       "      <th>uai</th>\n",
       "      <th>ltowvs</th>\n",
       "      <th>ivr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sid0</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>Momotaro</td>\n",
       "      <td>If you’ll believe me there was a time when the...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sid65</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Filial Girl</td>\n",
       "      <td>A girl once lived in the province of Echigo, w...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sid109</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Tongue-Cut Sparrow</td>\n",
       "      <td>Once upon a time there was an old man who live...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sid122</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Mallet</td>\n",
       "      <td>There were once two farmer men who were brothe...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sid210</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>Karma</td>\n",
       "      <td>The young man, Ito Tatewaki, was returning hom...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sid    nation language_family                   title  \\\n",
       "0    sid0  japanese       east_asia                Momotaro   \n",
       "1   sid65  japanese       east_asia         The Filial Girl   \n",
       "2  sid109  japanese       east_asia  The Tongue-Cut Sparrow   \n",
       "3  sid122  japanese       east_asia              The Mallet   \n",
       "4  sid210  japanese       east_asia                   Karma   \n",
       "\n",
       "                                                text   pdi   idv   mas   uai  \\\n",
       "0  If you’ll believe me there was a time when the...  54.0  46.0  95.0  92.0   \n",
       "1  A girl once lived in the province of Echigo, w...  54.0  46.0  95.0  92.0   \n",
       "2  Once upon a time there was an old man who live...  54.0  46.0  95.0  92.0   \n",
       "3  There were once two farmer men who were brothe...  54.0  46.0  95.0  92.0   \n",
       "4  The young man, Ito Tatewaki, was returning hom...  54.0  46.0  95.0  92.0   \n",
       "\n",
       "     ltowvs        ivr  \n",
       "0  87.90932  41.741071  \n",
       "1  87.90932  41.741071  \n",
       "2  87.90932  41.741071  \n",
       "3  87.90932  41.741071  \n",
       "4  87.90932  41.741071  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_hofstede = pd.read_csv(save_progress+'stories_hofstede.csv')\n",
    "stories_hofstede.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc3c6f",
   "metadata": {},
   "source": [
    "# Lemma Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd78a7",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92181bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_counts = utils.make_posdict(lemma_counts,'n')\n",
    "verb_counts = utils.make_posdict(lemma_counts,'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f1172c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bynation = utils.group_lemmacounts_bynation(noun_counts,list(stories.nation.unique())).to_csv(save_progress+\"nouns_bynation.csv\",index=True)\n",
    "nouns_bynation = pd.read_csv(save_progress+\"nouns_bynation.csv\",index_col=0)\n",
    "# verbs_bynation = utils.group_lemmacounts_bynation(verb_counts,list(stories.nation.unique())).to_csv(save_progress+\"verbs_bynation.csv\",index=True)\n",
    "# verbs_bynation = pd.read_csv(save_progress+\"verbs_bynation.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a15f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bylangfam = nouns_bynation.T.copy().reset_index().rename(columns={'index':'Nation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "68eb8e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_bylangfam.loc[0,'Nation'] in grouped_regions[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e7004fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bylangfam = nouns_bynation.T.copy().reset_index().rename(columns={'index':'Nation'})\n",
    "lang_fam = []\n",
    "for i in nouns_bylangfam.index:\n",
    "    hasfam = False\n",
    "    for key in grouped_regions.keys():\n",
    "        if nouns_bylangfam.loc[i,'Nation'] in grouped_regions[key]:\n",
    "            lang_fam.append(key)\n",
    "            hasfam = True\n",
    "    if not hasfam:\n",
    "        lang_fam.append(np.nan)\n",
    "nouns_bylangfam['language_family'] = lang_fam\n",
    "nouns_bylangfam = nouns_bylangfam.groupby('language_family').mean().T\n",
    "nouns_bylangfam.to_csv(save_progress+\"nouns_bylangfam.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6e200b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>language_family</th>\n",
       "      <th>albanian</th>\n",
       "      <th>armenic</th>\n",
       "      <th>austronesian</th>\n",
       "      <th>bantu</th>\n",
       "      <th>celtic</th>\n",
       "      <th>chadic</th>\n",
       "      <th>east_asia</th>\n",
       "      <th>germanic</th>\n",
       "      <th>hellenic</th>\n",
       "      <th>hindustani</th>\n",
       "      <th>italic</th>\n",
       "      <th>native_american</th>\n",
       "      <th>native_cana</th>\n",
       "      <th>semitic</th>\n",
       "      <th>slavic</th>\n",
       "      <th>turkic</th>\n",
       "      <th>uralic</th>\n",
       "      <th>urgic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>princess</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narran</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wyah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mahthi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humpy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eagle_hawk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5066 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "language_family  albanian  armenic  austronesian  bantu    celtic  chadic  \\\n",
       "lemma                                                                       \n",
       "king                  0.0      0.0      0.000740    0.0  0.004363     0.0   \n",
       "would                 0.0      0.0      0.004792    0.0  0.004861     0.0   \n",
       "princess              0.0      0.0      0.000296    0.0  0.001545     0.0   \n",
       "could                 0.0      0.0      0.003274    0.0  0.003762     0.0   \n",
       "mother                0.0      0.0      0.001989    0.0  0.001304     0.0   \n",
       "...                   ...      ...           ...    ...       ...     ...   \n",
       "narran                0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "wyah                  0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "mahthi                0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "humpy                 0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "eagle_hawk            0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "\n",
       "language_family  east_asia  germanic  hellenic  hindustani    italic  \\\n",
       "lemma                                                                  \n",
       "king              0.002551  0.003541  0.009419    0.008664  0.004108   \n",
       "would             0.005725  0.004836  0.007731    0.005062  0.002462   \n",
       "princess          0.001751  0.001408  0.002133    0.002406  0.002019   \n",
       "could             0.004391  0.004301  0.006798    0.003195  0.001771   \n",
       "mother            0.002587  0.001709  0.003310    0.001660  0.000754   \n",
       "...                    ...       ...       ...         ...       ...   \n",
       "narran            0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "wyah              0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "mahthi            0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "humpy             0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "eagle_hawk        0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "language_family  native_american  native_cana  semitic    slavic  turkic  \\\n",
       "lemma                                                                      \n",
       "king                    0.001221          0.0      0.0  0.003378     0.0   \n",
       "would                   0.007762          0.0      0.0  0.002480     0.0   \n",
       "princess                0.000000          0.0      0.0  0.002368     0.0   \n",
       "could                   0.005866          0.0      0.0  0.001914     0.0   \n",
       "mother                  0.002365          0.0      0.0  0.001464     0.0   \n",
       "...                          ...          ...      ...       ...     ...   \n",
       "narran                  0.000000          0.0      0.0  0.000000     0.0   \n",
       "wyah                    0.000000          0.0      0.0  0.000000     0.0   \n",
       "mahthi                  0.000000          0.0      0.0  0.000000     0.0   \n",
       "humpy                   0.000000          0.0      0.0  0.000000     0.0   \n",
       "eagle_hawk              0.000000          0.0      0.0  0.000000     0.0   \n",
       "\n",
       "language_family  uralic  urgic  \n",
       "lemma                           \n",
       "king                0.0    0.0  \n",
       "would               0.0    0.0  \n",
       "princess            0.0    0.0  \n",
       "could               0.0    0.0  \n",
       "mother              0.0    0.0  \n",
       "...                 ...    ...  \n",
       "narran              0.0    0.0  \n",
       "wyah                0.0    0.0  \n",
       "mahthi              0.0    0.0  \n",
       "humpy               0.0    0.0  \n",
       "eagle_hawk          0.0    0.0  \n",
       "\n",
       "[5066 rows x 18 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_bylangfam.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bynation = pd.read_csv(save_progress+\"nouns_bynation.csv\",index_col=0)\n",
    "# verbs_bynation = pd.read_csv(save_progress+\"verbs_bynation.csv\",index_col=0)\n",
    "nouns_bylangfam = pd.read_csv(save_progress+\"nouns_bylangfam.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a200da7",
   "metadata": {},
   "source": [
    "## % of stories that mention x lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d47c61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacount = pd.DataFrame()\n",
    "for i in stories.index:\n",
    "    lemma_count = pd.DataFrame(pd.Series(stories.iloc[i]['phrased'].strip(\"[]\").replace('\\'',\"\").split(\", \")).value_counts())\n",
    "    lemma_count.columns = ['sid'+str(i)]\n",
    "    stories_lemmacount = pd.merge(stories_lemmacount,lemma_count,left_index=True,right_index=True,how=\"outer\")\n",
    "stories_lemmacount = stories_lemmacount.fillna(0)\n",
    "\n",
    "stories_lemmacount = stories_lemmacount.reset_index()\n",
    "stories_lemmacount = stories_lemmacount.rename(columns={'index':'lemma'})\n",
    "stories_lemmacount = stories_lemmacount.set_index('lemma')\n",
    "stories_lemmacount.to_csv(save_progress+\"stories_lemmacount.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9820f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacount = pd.read_csv(save_progress+\"stories_lemmacount.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "96672071",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacountT = stories_lemmacount.copy().T.reset_index()\n",
    "stories_lemmacountT = stories_lemmacountT.rename(columns={'level_0':'sid'})\n",
    "stories_lemmacountT = stories_lemmacountT.set_index('sid')\n",
    "stories_lemmacountT = pd.merge(stories_lemmacountT,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "stories_lemmacountT = stories_lemmacountT.rename(columns = {'nation_y':'nation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3e793c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sid0', 'sid2184', 'sid2577'], dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_lemmacount.columns[np.where(stories_lemmacount.loc['momotaro']!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c7389629",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_storycount = dict(stories.groupby('nation').count()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8fd662f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.read_csv(data+'bigrams.csv').set_index('bigram').rename(columns={' count':'count'})\n",
    "bigrams['count'] = bigrams['count'] + 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e876b",
   "metadata": {},
   "source": [
    "## percentile of group in lemma usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7fb31",
   "metadata": {},
   "source": [
    "count(lemma) / len(story words) --> avg freq --> percentile of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bf1a6",
   "metadata": {},
   "source": [
    "\"nation a is in the top n% of users of lemma x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "94161c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmafreq = stories_lemmacount.copy()\n",
    "stories_lemmafreq = stories_lemmafreq.div(stories_lemmacount.sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "24acadb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid0</th>\n",
       "      <th>sid2184</th>\n",
       "      <th>sid2577</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aalborg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aarhus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aasvo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuur</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuyder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuyderzee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwanzigers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33763 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sid0  sid2184  sid2577\n",
       "lemma                             \n",
       "aalborg      0.0      0.0      0.0\n",
       "aard         0.0      0.0      0.0\n",
       "aarhus       0.0      0.0      0.0\n",
       "aaron        0.0      0.0      0.0\n",
       "aasvo        0.0      0.0      0.0\n",
       "...          ...      ...      ...\n",
       "zuur         0.0      0.0      0.0\n",
       "zuya         0.0      0.0      0.0\n",
       "zuyder       0.0      0.0      0.0\n",
       "zuyderzee    0.0      0.0      0.0\n",
       "zwanzigers   0.0      0.0      0.0\n",
       "\n",
       "[33763 rows x 3 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_lemmafreq[stories_lemmafreq.columns[np.where(stories_lemmafreq.loc['momotaro']!=0)[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "6af3d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *! groupby\n",
    "groupby = 'nation' # nation, language_family\n",
    "wrt = 'nation' # nation/language_family, lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "e0731663",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemmamean = pd.merge(stories_lemmafreq.T,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "nation_lemmamean = nation_lemmamean.rename(columns={'nation_y':'nation'})\n",
    "nation_lemmamean = nation_lemmamean.groupby(groupby).mean()\n",
    "nation_lemmameanT= nation_lemmamean.T\n",
    "\n",
    "nation_lemmamean_save = nation_lemmameanT\n",
    "nation_lemmamean_save['englishness'] = lemma_englishness\n",
    "nation_lemmamean_save['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)\n",
    "nation_lemmamean_save.to_csv(save_progress+'nation_lemmamean.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "26fea9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_percentile = pd.DataFrame()\n",
    "if wrt == 'nation' or wrt == 'language_family':\n",
    "    for col in nation_lemmameanT:\n",
    "        lemma_percentile[col] = [percentileofscore(nation_lemmameanT[col], value) for value in nation_lemmameanT[col]]\n",
    "elif wrt == 'lemma':\n",
    "    for col in nation_lemmamean:\n",
    "        lemma_percentile[col] = [percentileofscore(nation_lemmamean[col], value) for value in nation_lemmamean[col]]\n",
    "    lemma_percentile = lemma_percentile.T\n",
    "lemma_percentile.columns = list(nation_lemmamean.index.values)\n",
    "# lemma_percentile['englishness'] = lemma_englishness\n",
    "# lemma_percentile['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)\n",
    "lemma_percentile = lemma_percentile.rename(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "cdd7f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile['englishness'] = lemma_englishness\n",
    "nation_lemma_lemmapercentile['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "4ac5750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile.to_csv(save_progress+\"nation_lemma_lemmapercentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7c10f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_percentile.to_csv(save_progress+f\"{groupby}_lemma_{wrt}percentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c12c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile = pd.read_csv(save_progress+\"nation_lemma_lemmapercentile.csv\",index_col=0)\n",
    "nation_lemma_nationpercentile = pd.read_csv(save_progress+\"nation_lemma_nationpercentile.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003cad1",
   "metadata": {},
   "source": [
    "uniqueness to group = langfam/nation percentile <br>\n",
    "uniqueness within group = lemma percentile <br>\n",
    "<br>\n",
    "lemma_uniquness = unique1 x unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "1fbad35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation = pd.DataFrame(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))\n",
    "for col in nation_lemma_lemmapercentile.columns:\n",
    "    lemma_unique_nation[col] = nation_lemma_lemmapercentile[col].values+.5*nation_lemma_nationpercentile[col].values\n",
    "lemma_unique_nation = lemma_unique_nation.rename(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "9a23aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation['englishness'] = lemma_englishness\n",
    "lemma_unique_nation['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "8f7b4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation.to_csv(save_progress+'lemma_unique_nation.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9de2e",
   "metadata": {},
   "source": [
    "### language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1b0205b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile = pd.merge(stories_lemmafreq.T,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.rename(columns={'nation_y':'nation'})\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.groupby('language_family').mean()\n",
    "for col in langfam_lemmapercentile:\n",
    "    langfam_lemmapercentile[col] = [percentileofscore(langfam_lemmapercentile[col], value) for value in langfam_lemmapercentile[col]]\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "23663127",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile['englishness'] = lemma_englishness\n",
    "langfam_lemmapercentile['common'] = langfam_lemmapercentile[stories.language_family.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8200121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile.to_csv(save_progress+\"langfam_lemmapercentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "611cc5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>albanian</th>\n",
       "      <th>armenic</th>\n",
       "      <th>austronesian</th>\n",
       "      <th>bantu</th>\n",
       "      <th>celtic</th>\n",
       "      <th>chadic</th>\n",
       "      <th>east_asia</th>\n",
       "      <th>germanic</th>\n",
       "      <th>hellenic</th>\n",
       "      <th>hindustani</th>\n",
       "      <th>italic</th>\n",
       "      <th>native_american</th>\n",
       "      <th>native_cana</th>\n",
       "      <th>semitic</th>\n",
       "      <th>slavic</th>\n",
       "      <th>turkic</th>\n",
       "      <th>uralic</th>\n",
       "      <th>urgic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aalborg</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aard</th>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>100.0</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          albanian    armenic  austronesian  bantu     celtic     chadic  \\\n",
       "aalborg  50.000000  50.000000     50.000000   50.0  50.000000  50.000000   \n",
       "aard     44.444444  44.444444     94.444444  100.0  44.444444  44.444444   \n",
       "\n",
       "          east_asia   germanic   hellenic  hindustani     italic  \\\n",
       "aalborg  100.000000  50.000000  50.000000   50.000000  50.000000   \n",
       "aard      88.888889  44.444444  44.444444   44.444444  44.444444   \n",
       "\n",
       "         native_american  native_cana    semitic     slavic     turkic  \\\n",
       "aalborg        50.000000    50.000000  50.000000  50.000000  50.000000   \n",
       "aard           44.444444    44.444444  44.444444  44.444444  44.444444   \n",
       "\n",
       "            uralic      urgic  \n",
       "aalborg  50.000000  50.000000  \n",
       "aard     44.444444  44.444444  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfam_lemmapercentile = pd.read_csv(save_progress+\"langfam_lemmapercentile.csv\",index_col=0)\n",
    "langfam_lemmapercentile.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434baf26",
   "metadata": {},
   "source": [
    "# LIWC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581f3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict = utils.readDict(data+'LIWC2007_English100131.dic')\n",
    "# power = ['king','queen','prince','princess','servant','master','lord','throne','emperor','palace','sultan','royal','majesty','tsar']\n",
    "royalty = ['king*','queen*','prince*','princess*','servant*','master*','lord*','throne*','emperor*','palace*','sultan*','royal*','majesty*','tsar*']\n",
    "hero = ['hero*','warrior*','knight*','beast*','brave*','courage*']\n",
    "edited_dict = liwc_dict[0].copy()\n",
    "# for word in power:\n",
    "#     if word in edited_dict.keys():\n",
    "#         edited_dict[word] += ['power']\n",
    "#     else:\n",
    "#         edited_dict[word] = ['power']\n",
    "for word in royalty:\n",
    "    if word in edited_dict.keys():\n",
    "        edited_dict[word] += ['royalty']\n",
    "    else:\n",
    "        edited_dict[word] = ['royalty']\n",
    "for word in hero:\n",
    "    if word in edited_dict.keys():\n",
    "        edited_dict[word] += ['hero']\n",
    "    else:\n",
    "        edited_dict[word] = ['hero']\n",
    "\n",
    "edited_values = [['funct'], ['pronoun'], ['ppron'], ['i'], ['we'], ['you'], ['shehe'], ['they'], ['ipron'], ['article'], ['verb'], ['auxverb'], ['past'], ['present'], ['future'], ['adverb'], ['preps'], ['conj'], ['negate'], ['quant'], ['number'], ['swear'], ['social'], ['family'], ['friend'], ['humans'], ['affect'], ['posemo'], ['negemo'], ['anx'], ['anger'], ['sad'], ['cogmech'], ['insight'], ['cause'], ['discrep'], ['tentat'], ['certain'], ['inhib'], ['incl'], ['excl'], ['percept'], ['see'], ['hear'], ['feel'], ['bio'], ['body'], ['health'], ['sexual'], ['ingest'], ['relativ'], ['motion'], ['space'], ['time'], ['work'], ['achieve'], ['leisure'], ['home'], ['money'], ['relig'], ['death'], ['assent'], ['nonfl'], ['filler'],\n",
    "['power'], ['royalty'], ['hero']]\n",
    "helper_odict = collections.OrderedDict()\n",
    "for i in range(len(edited_values)):\n",
    "    helper_odict[i] = edited_values[i]\n",
    "\n",
    "mydict = (edited_dict, helper_odict.values())\n",
    "# animals: horse, bird, dragon, beast, witch, fish, tortoise, lion, puma, snake, rabbit, mouse, hare, stag, serpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e988fc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('a', ['funct', 'article']),\n",
       "              ('abandon*', ['affect', 'negemo', 'sad', 'cogmech', 'inhib']),\n",
       "              ('abdomen*', ['bio', 'body']),\n",
       "              ('abilit*', ['achieve']),\n",
       "              ('able*', ['achieve']),\n",
       "              ('abortion*', ['bio', 'health', 'sexual']),\n",
       "              ('about', ['funct', 'adverb', 'preps']),\n",
       "              ('above', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('abrupt*', ['time', 'relativ']),\n",
       "              ('abs', ['bio', 'body']),\n",
       "              ('absent*', ['work']),\n",
       "              ('absolute', ['cogmech', 'certain']),\n",
       "              ('absolutely',\n",
       "               ['funct', 'adverb', 'cogmech', 'certain', 'assent']),\n",
       "              ('abstain*', ['cogmech', 'inhib']),\n",
       "              ('abuse*', ['affect', 'negemo', 'anger']),\n",
       "              ('abusi*', ['affect', 'negemo', 'anger']),\n",
       "              ('academ*', ['work']),\n",
       "              ('accept', ['affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('accepta*', ['affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('accepted',\n",
       "               ['verb', 'past', 'affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('accepting', ['affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('accepts', ['affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('accomplish*', ['work', 'achieve']),\n",
       "              ('account*', ['money']),\n",
       "              ('accura*', ['cogmech', 'certain']),\n",
       "              ('ace', ['achieve']),\n",
       "              ('ache*', ['affect', 'negemo', 'sad', 'bio', 'health']),\n",
       "              ('achiev*', ['work', 'achieve']),\n",
       "              ('aching', ['affect', 'negemo', 'sad', 'bio', 'health']),\n",
       "              ('acid*', ['percept']),\n",
       "              ('acknowledg*', ['cogmech', 'insight']),\n",
       "              ('acne', ['bio', 'health']),\n",
       "              ('acquainta*', ['social', 'friend']),\n",
       "              ('acquir*', ['achieve']),\n",
       "              ('acquisition*', ['achieve']),\n",
       "              ('acrid*', ['percept']),\n",
       "              ('across', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('act', ['relativ', 'motion']),\n",
       "              ('action*', ['motion', 'relativ']),\n",
       "              ('activat*', ['cogmech', 'cause']),\n",
       "              ('active*', ['affect', 'posemo']),\n",
       "              ('actor*', ['leisure']),\n",
       "              ('actress*', ['leisure']),\n",
       "              ('actually', ['funct', 'adverb']),\n",
       "              ('add', ['cogmech', 'incl']),\n",
       "              ('addict*', ['bio', 'health']),\n",
       "              ('addit*', ['cogmech', 'incl']),\n",
       "              ('address', ['home']),\n",
       "              ('adequa*', ['achieve']),\n",
       "              ('adjust*', ['cogmech', 'insight']),\n",
       "              ('administrat*', ['work']),\n",
       "              ('admir*', ['affect', 'posemo']),\n",
       "              ('admit', ['verb', 'present', 'social', 'cogmech', 'insight']),\n",
       "              ('admits', ['verb', 'present', 'social', 'cogmech', 'insight']),\n",
       "              ('admitted', ['verb', 'past', 'social', 'cogmech', 'insight']),\n",
       "              ('admitting', ['social', 'cogmech', 'insight']),\n",
       "              ('ador*', ['affect', 'posemo']),\n",
       "              ('adult', ['social', 'humans']),\n",
       "              ('adults', ['social', 'humans']),\n",
       "              ('advanc*', ['motion', 'relativ', 'achieve']),\n",
       "              ('advantag*', ['affect', 'posemo', 'achieve']),\n",
       "              ('adventur*', ['affect', 'posemo']),\n",
       "              ('advers*', ['affect', 'negemo']),\n",
       "              ('advertising', ['work']),\n",
       "              ('advice', ['social']),\n",
       "              ('advil', ['bio', 'health']),\n",
       "              ('advis*', ['social', 'work']),\n",
       "              ('aerobic*', ['leisure']),\n",
       "              ('affair*', ['social']),\n",
       "              ('affect', ['cogmech', 'cause']),\n",
       "              ('affected', ['verb', 'past', 'cogmech', 'cause']),\n",
       "              ('affecting', ['cogmech', 'cause']),\n",
       "              ('affection*', ['affect', 'posemo']),\n",
       "              ('affects', ['cogmech', 'cause']),\n",
       "              ('afraid', ['affect', 'negemo', 'anx']),\n",
       "              ('after', ['funct', 'preps', 'time', 'relativ']),\n",
       "              ('afterlife*', ['time', 'relativ', 'relig']),\n",
       "              ('aftermath*', ['time', 'relativ']),\n",
       "              ('afternoon*', ['time', 'relativ']),\n",
       "              ('afterthought*', ['cogmech', 'insight', 'time', 'relativ']),\n",
       "              ('afterward*', ['time', 'relativ']),\n",
       "              ('again', ['funct', 'adverb', 'time', 'relativ']),\n",
       "              ('against', ['funct', 'preps']),\n",
       "              ('age', ['time', 'relativ']),\n",
       "              ('aged', ['time', 'relativ']),\n",
       "              ('agent', ['work']),\n",
       "              ('agents', ['work']),\n",
       "              ('ages', ['time', 'relativ']),\n",
       "              ('aggravat*', ['affect', 'negemo', 'anger', 'cogmech', 'cause']),\n",
       "              ('aggress*', ['affect', 'negemo', 'anger']),\n",
       "              ('aging', ['time', 'relativ']),\n",
       "              ('agitat*', ['affect', 'negemo', 'anger']),\n",
       "              ('agnost*', ['relig']),\n",
       "              ('ago', ['time', 'relativ']),\n",
       "              ('agoniz*', ['affect', 'negemo', 'sad']),\n",
       "              ('agony', ['affect', 'negemo', 'sad']),\n",
       "              ('agree', ['affect', 'posemo', 'assent']),\n",
       "              ('agreeab*', ['affect', 'posemo']),\n",
       "              ('agreed', ['affect', 'posemo']),\n",
       "              ('agreeing', ['affect', 'posemo']),\n",
       "              ('agreement*', ['affect', 'posemo']),\n",
       "              ('agrees', ['affect', 'posemo']),\n",
       "              ('ah', ['assent']),\n",
       "              ('ahead', ['funct', 'preps', 'time', 'relativ', 'achieve']),\n",
       "              ('aids', ['bio', 'health', 'sexual']),\n",
       "              (\"ain't\", ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('aint', ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('air', ['relativ', 'space']),\n",
       "              ('alarm*', ['affect', 'negemo', 'anx']),\n",
       "              ('alcohol*', ['bio', 'health', 'ingest']),\n",
       "              ('alive', ['bio', 'health', 'death']),\n",
       "              ('all', ['funct', 'quant', 'cogmech', 'certain']),\n",
       "              ('alla', ['relig']),\n",
       "              ('allah*', ['relig']),\n",
       "              ('allerg*', ['bio', 'health']),\n",
       "              ('allot', ['funct', 'quant', 'cogmech', 'tentat']),\n",
       "              ('allow*', ['cogmech', 'cause']),\n",
       "              ('almost', ['cogmech', 'tentat']),\n",
       "              ('alone', ['affect', 'negemo', 'sad']),\n",
       "              ('along', ['funct', 'preps', 'cogmech', 'incl']),\n",
       "              ('alot', ['funct', 'article', 'quant', 'cogmech', 'tentat']),\n",
       "              ('already', ['time', 'relativ']),\n",
       "              ('alright*', ['affect', 'posemo', 'assent']),\n",
       "              ('also', ['funct', 'adverb', 'conj']),\n",
       "              ('altar*', ['relig']),\n",
       "              ('although', ['funct', 'conj']),\n",
       "              ('altogether', ['cogmech', 'certain']),\n",
       "              ('always', ['cogmech', 'certain', 'time', 'relativ']),\n",
       "              ('am', ['verb', 'funct', 'auxverb', 'present']),\n",
       "              ('amaz*', ['affect', 'posemo']),\n",
       "              ('ambigu*', ['cogmech', 'tentat']),\n",
       "              ('ambiti*', ['work', 'achieve']),\n",
       "              ('amen', ['relig']),\n",
       "              ('amigo*', ['social', 'friend']),\n",
       "              ('amish', ['relig']),\n",
       "              ('among*', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('amor*', ['affect', 'posemo']),\n",
       "              ('amount*', ['quant']),\n",
       "              ('amput*', ['bio', 'health']),\n",
       "              ('amus*', ['affect', 'posemo', 'leisure']),\n",
       "              ('an', ['funct', 'article']),\n",
       "              ('anal', ['cogmech', 'inhib', 'bio', 'body']),\n",
       "              ('analy*', ['cogmech', 'insight']),\n",
       "              ('ancient*', ['time', 'relativ']),\n",
       "              ('and', ['funct', 'conj', 'cogmech', 'incl']),\n",
       "              ('angel', ['relig']),\n",
       "              ('angelic*', ['relig']),\n",
       "              ('angels', ['relig']),\n",
       "              ('anger*', ['affect', 'negemo', 'anger']),\n",
       "              ('angr*', ['affect', 'negemo', 'anger']),\n",
       "              ('anguish*', ['affect', 'negemo', 'anx']),\n",
       "              ('ankle*', ['bio', 'body']),\n",
       "              ('annoy*', ['affect', 'negemo', 'anger']),\n",
       "              ('annual*', ['time', 'relativ']),\n",
       "              ('anorexi*', ['bio', 'health', 'ingest']),\n",
       "              ('another', ['funct', 'quant']),\n",
       "              ('answer*', ['cogmech', 'insight']),\n",
       "              ('antacid*', ['bio', 'health']),\n",
       "              ('antagoni*', ['affect', 'negemo', 'anger']),\n",
       "              ('antidepressant*', ['bio', 'health']),\n",
       "              ('anus*', ['bio', 'body']),\n",
       "              ('anxi*', ['affect', 'negemo', 'anx']),\n",
       "              ('any', ['funct', 'quant', 'cogmech', 'tentat']),\n",
       "              ('anybod*',\n",
       "               ['funct', 'pronoun', 'ipron', 'social', 'cogmech', 'tentat']),\n",
       "              ('anyhow', ['cogmech', 'tentat']),\n",
       "              ('anymore', ['funct', 'quant', 'relativ', 'time']),\n",
       "              ('anyone*',\n",
       "               ['funct', 'pronoun', 'ipron', 'social', 'cogmech', 'tentat']),\n",
       "              ('anything', ['funct', 'pronoun', 'ipron', 'cogmech', 'tentat']),\n",
       "              ('anytime', ['cogmech', 'tentat', 'time', 'relativ']),\n",
       "              ('anyway*', ['funct', 'adverb']),\n",
       "              ('anywhere',\n",
       "               ['funct', 'adverb', 'cogmech', 'tentat', 'space', 'relativ']),\n",
       "              ('aok', ['affect', 'posemo', 'assent']),\n",
       "              ('apart', ['space', 'relativ']),\n",
       "              ('apartment*', ['leisure', 'home']),\n",
       "              ('apath*', ['affect', 'negemo']),\n",
       "              ('apolog*', ['social']),\n",
       "              ('appall*', ['affect', 'negemo']),\n",
       "              ('apparent', ['cogmech', 'certain']),\n",
       "              ('apparently', ['funct', 'adverb', 'cogmech', 'tentat']),\n",
       "              ('appear',\n",
       "               ['verb', 'present', 'cogmech', 'tentat', 'motion', 'relativ']),\n",
       "              ('appeared',\n",
       "               ['verb', 'past', 'cogmech', 'tentat', 'motion', 'relativ']),\n",
       "              ('appearing', ['cogmech', 'tentat', 'motion', 'relativ']),\n",
       "              ('appears',\n",
       "               ['verb', 'present', 'cogmech', 'tentat', 'motion', 'relativ']),\n",
       "              ('appendic*', ['bio', 'health']),\n",
       "              ('appendix', ['bio', 'body']),\n",
       "              ('appeti*', ['bio', 'ingest']),\n",
       "              ('applicant*', ['work']),\n",
       "              ('applicat*', ['work']),\n",
       "              ('appreciat*', ['affect', 'posemo', 'cogmech', 'insight']),\n",
       "              ('apprehens*', ['affect', 'negemo', 'anx']),\n",
       "              ('apprentic*', ['work']),\n",
       "              ('approach*', ['motion', 'relativ']),\n",
       "              ('approv*', ['achieve']),\n",
       "              ('approximat*', ['cogmech', 'tentat']),\n",
       "              ('april', ['time', 'relativ']),\n",
       "              ('arbitrar*', ['cogmech', 'tentat']),\n",
       "              ('arch', ['bio', 'body']),\n",
       "              ('are', ['verb', 'funct', 'auxverb', 'present']),\n",
       "              ('area*', ['space', 'relativ']),\n",
       "              (\"aren't\", ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('arent', ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('argh*', ['affect', 'negemo', 'anger']),\n",
       "              ('argu*', ['social', 'affect', 'negemo', 'anger']),\n",
       "              ('arm', ['bio', 'body']),\n",
       "              ('armies', ['social']),\n",
       "              ('armpit*', ['bio', 'body']),\n",
       "              ('arms*', ['bio', 'body']),\n",
       "              ('army', ['social']),\n",
       "              ('aroma*', ['percept']),\n",
       "              ('around',\n",
       "               ['funct',\n",
       "                'adverb',\n",
       "                'preps',\n",
       "                'cogmech',\n",
       "                'incl',\n",
       "                'space',\n",
       "                'relativ']),\n",
       "              ('arous*', ['bio', 'body', 'sexual']),\n",
       "              ('arrival*', ['motion', 'relativ']),\n",
       "              ('arrive', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('arrived', ['verb', 'past', 'motion', 'relativ']),\n",
       "              ('arrives', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('arriving', ['motion', 'relativ']),\n",
       "              ('arrogan*', ['affect', 'negemo', 'anger']),\n",
       "              ('arse', ['bio', 'body', 'swear']),\n",
       "              ('arsehole*', ['swear']),\n",
       "              ('arses', ['bio', 'body', 'swear']),\n",
       "              ('art', ['leisure']),\n",
       "              ('arter*', ['bio', 'body']),\n",
       "              ('arthr*', ['bio', 'health']),\n",
       "              ('artist*', ['leisure']),\n",
       "              ('arts', ['leisure']),\n",
       "              ('as', ['funct', 'preps', 'conj']),\n",
       "              ('asham*', ['affect', 'negemo', 'anx']),\n",
       "              ('ask', ['verb', 'present', 'social']),\n",
       "              ('asked', ['verb', 'past', 'social']),\n",
       "              ('asking', ['social']),\n",
       "              ('asks', ['verb', 'present', 'social']),\n",
       "              ('asleep', ['bio', 'body']),\n",
       "              ('aspirin*', ['bio', 'health']),\n",
       "              ('ass', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('assault*', ['affect', 'negemo', 'anger']),\n",
       "              ('assembl*', ['social']),\n",
       "              ('asses', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('asshole*', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('assign*', ['work']),\n",
       "              ('assistan*', ['work']),\n",
       "              ('associat*', ['work']),\n",
       "              ('assum*', ['cogmech', 'insight', 'tentat']),\n",
       "              ('assur*', ['affect', 'posemo', 'cogmech', 'certain']),\n",
       "              ('asthma*', ['bio', 'health']),\n",
       "              ('at', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('ate', ['verb', 'past', 'bio', 'ingest']),\n",
       "              ('athletic*', ['leisure']),\n",
       "              ('atho', ['funct', 'conj']),\n",
       "              ('atm', ['money']),\n",
       "              ('atms', ['money']),\n",
       "              ('atop', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('attachment*', ['affect', 'posemo']),\n",
       "              ('attack*', ['affect', 'negemo', 'anger']),\n",
       "              ('attain*', ['achieve']),\n",
       "              ('attempt*', ['achieve']),\n",
       "              ('attend', ['motion', 'relativ']),\n",
       "              ('attended', ['motion', 'relativ']),\n",
       "              ('attending', ['motion', 'relativ']),\n",
       "              ('attends', ['motion', 'relativ']),\n",
       "              ('attent*', ['cogmech', 'insight']),\n",
       "              ('attract*', ['affect', 'posemo']),\n",
       "              ('attribut*', ['cogmech', 'cause']),\n",
       "              ('auction*', ['money']),\n",
       "              ('audibl*', ['percept', 'hear']),\n",
       "              ('audio*', ['percept', 'hear']),\n",
       "              ('audit', ['money']),\n",
       "              ('audited', ['money']),\n",
       "              ('auditing', ['money']),\n",
       "              ('auditor', ['money']),\n",
       "              ('auditorium*', ['work']),\n",
       "              ('auditors', ['money']),\n",
       "              ('audits', ['money']),\n",
       "              ('august', ['time', 'relativ']),\n",
       "              ('aunt*', ['social', 'family']),\n",
       "              ('authorit*', ['achieve']),\n",
       "              ('autops*', ['death']),\n",
       "              ('autumn', ['time', 'relativ']),\n",
       "              ('aversi*', ['affect', 'negemo', 'anx']),\n",
       "              ('avert*', ['cogmech', 'inhib']),\n",
       "              ('avoid*', ['affect', 'negemo', 'anx', 'cogmech', 'inhib']),\n",
       "              ('aw', ['assent']),\n",
       "              ('award*', ['affect', 'posemo', 'work', 'achieve']),\n",
       "              ('aware*', ['cogmech', 'insight']),\n",
       "              ('away', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('awesome', ['affect', 'posemo', 'assent']),\n",
       "              ('awful', ['affect', 'negemo']),\n",
       "              ('awhile', ['time', 'relativ']),\n",
       "              ('awkward*', ['affect', 'negemo', 'anx']),\n",
       "              ('babe*', ['social', 'humans']),\n",
       "              ('babies', ['social', 'humans']),\n",
       "              ('baby*', ['social', 'humans']),\n",
       "              ('back', ['funct', 'adverb', 'time', 'relativ']),\n",
       "              ('backward*', ['space', 'relativ']),\n",
       "              ('backyard', ['home']),\n",
       "              ('bad', ['affect', 'negemo']),\n",
       "              ('bake*', ['bio', 'ingest', 'home']),\n",
       "              ('baking', ['bio', 'ingest', 'home']),\n",
       "              ('balcon*', ['home']),\n",
       "              ('bald', ['bio', 'body']),\n",
       "              ('ball', ['leisure']),\n",
       "              ('ballet*', ['leisure']),\n",
       "              ('bambino*', ['social', 'humans']),\n",
       "              ('ban', ['cogmech', 'inhib']),\n",
       "              ('band', ['social', 'leisure']),\n",
       "              ('bandage*', ['bio', 'health']),\n",
       "              ('bandaid', ['bio', 'health']),\n",
       "              ('bands', ['social', 'leisure']),\n",
       "              ('bank*', ['money']),\n",
       "              ('banned', ['cogmech', 'inhib']),\n",
       "              ('banning', ['cogmech', 'inhib']),\n",
       "              ('bans', ['cogmech', 'inhib']),\n",
       "              ('baptis*', ['relig']),\n",
       "              ('baptiz*', ['relig']),\n",
       "              ('bar', ['bio', 'ingest', 'leisure']),\n",
       "              ('barely', ['cogmech', 'tentat']),\n",
       "              ('bargain*', ['money']),\n",
       "              ('barrier*', ['cogmech', 'inhib']),\n",
       "              ('bars', ['bio', 'ingest', 'leisure']),\n",
       "              ('baseball*', ['leisure']),\n",
       "              ('based', ['cogmech', 'cause']),\n",
       "              ('bases', ['cogmech', 'cause']),\n",
       "              ('bashful*', ['affect', 'negemo']),\n",
       "              ('basically', ['funct', 'adverb']),\n",
       "              ('basis', ['cogmech', 'cause']),\n",
       "              ('basketball*', ['leisure']),\n",
       "              ('bastard*', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('bath*', ['leisure', 'home']),\n",
       "              ('battl*', ['affect', 'negemo', 'anger']),\n",
       "              ('be', ['verb', 'funct', 'auxverb']),\n",
       "              ('beach*', ['leisure']),\n",
       "              ('beat', ['achieve']),\n",
       "              ('beaten', ['affect', 'negemo', 'anger', 'work', 'achieve']),\n",
       "              ('beaut*', ['affect', 'posemo', 'percept', 'see']),\n",
       "              ('became',\n",
       "               ['verb', 'funct', 'auxverb', 'past', 'cogmech', 'insight']),\n",
       "              ('because', ['funct', 'conj', 'cogmech', 'cause']),\n",
       "              ('become',\n",
       "               ['verb', 'funct', 'auxverb', 'present', 'cogmech', 'insight']),\n",
       "              ('becomes',\n",
       "               ['verb', 'funct', 'auxverb', 'present', 'cogmech', 'insight']),\n",
       "              ('becoming', ['verb', 'funct', 'auxverb', 'cogmech', 'insight']),\n",
       "              ('bed', ['home']),\n",
       "              ('bedding', ['home']),\n",
       "              ('bedroom*', ['home']),\n",
       "              ('beds', ['home']),\n",
       "              ('been', ['verb', 'funct', 'auxverb', 'past']),\n",
       "              ('beer*', ['bio', 'ingest', 'leisure']),\n",
       "              ('before', ['funct', 'preps', 'time', 'relativ']),\n",
       "              ('began', ['verb', 'past', 'time', 'relativ']),\n",
       "              ('beggar*', ['money']),\n",
       "              ('begging', ['money']),\n",
       "              ('begin', ['verb', 'present', 'time', 'relativ']),\n",
       "              ('beginn*', ['time', 'relativ']),\n",
       "              ('begins', ['verb', 'present', 'time', 'relativ']),\n",
       "              ('begun', ['time', 'relativ']),\n",
       "              ('behavio*', ['relativ', 'motion']),\n",
       "              ('behind', ['funct', 'preps']),\n",
       "              ('being', ['verb', 'funct', 'auxverb']),\n",
       "              ('belief*', ['cogmech', 'insight', 'relig']),\n",
       "              ('believe', ['verb', 'present', 'cogmech', 'insight']),\n",
       "              ('believed', ['verb', 'past', 'cogmech', 'insight']),\n",
       "              ('believes', ['verb', 'present', 'cogmech', 'insight']),\n",
       "              ('believing', ['cogmech', 'insight']),\n",
       "              ('bellies', ['bio', 'body']),\n",
       "              ('belly', ['bio', 'body']),\n",
       "              ('beloved', ['affect', 'posemo']),\n",
       "              ('below', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('bend', ['space', 'relativ']),\n",
       "              ('bending', ['space', 'relativ']),\n",
       "              ('bends', ['space', 'relativ']),\n",
       "              ('beneath', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('benefic*', ['affect', 'posemo']),\n",
       "              ('benefit', ['affect', 'posemo']),\n",
       "              ('benefits', ['affect', 'posemo', 'work']),\n",
       "              ('benefitt*', ['affect', 'posemo']),\n",
       "              ('benevolen*', ['affect', 'posemo']),\n",
       "              ('benign*', ['affect', 'posemo']),\n",
       "              ('bent', ['space', 'relativ']),\n",
       "              ('bereave*', ['death']),\n",
       "              ('beside', ['funct', 'preps', 'space', 'relativ']),\n",
       "              ('besides', ['funct', 'preps', 'quant', 'cogmech', 'discrep']),\n",
       "              ('best', ['affect', 'posemo', 'achieve', 'funct', 'quant']),\n",
       "              ('bet', ['cogmech', 'tentat', 'money']),\n",
       "              ('bets', ['cogmech', 'tentat', 'money']),\n",
       "              ('better', ['affect', 'posemo', 'achieve']),\n",
       "              ('betting', ['cogmech', 'tentat', 'money']),\n",
       "              ('between', ['funct', 'preps']),\n",
       "              ('beyond', ['funct', 'adverb', 'preps', 'space', 'relativ']),\n",
       "              ('bf*', ['social', 'friend']),\n",
       "              ('bi', ['bio', 'sexual']),\n",
       "              ('biannu*', ['time', 'relativ']),\n",
       "              ('bible*', ['relig']),\n",
       "              ('biblic*', ['relig']),\n",
       "              ('bicep*', ['bio', 'body']),\n",
       "              ('bicyc*', ['leisure']),\n",
       "              ('big', ['space', 'relativ']),\n",
       "              ('bigger', ['space', 'relativ']),\n",
       "              ('biggest', ['space', 'relativ']),\n",
       "              ('bike*', ['leisure']),\n",
       "              ('bill', ['money']),\n",
       "              ('billed', ['money']),\n",
       "              ('billing*', ['money']),\n",
       "              ('billion*', ['funct', 'number']),\n",
       "              ('bills', ['money']),\n",
       "              ('bimonth*', ['time', 'relativ']),\n",
       "              ('binding', ['cogmech', 'inhib']),\n",
       "              ('binge*', ['bio', 'health', 'ingest']),\n",
       "              ('binging', ['bio', 'health', 'ingest']),\n",
       "              ('biolog*', ['work']),\n",
       "              ('bipolar', ['bio', 'health']),\n",
       "              ('birdie*', ['leisure']),\n",
       "              ('birth*', ['time', 'relativ']),\n",
       "              ('bishop*', ['relig']),\n",
       "              ('bit', ['quant']),\n",
       "              ('bitch*', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('bits', ['quant']),\n",
       "              ('bitter*', ['affect', 'negemo', 'anger', 'percept']),\n",
       "              ('biweek*', ['time', 'relativ']),\n",
       "              ('biz', ['work']),\n",
       "              ('black', ['percept', 'see']),\n",
       "              ('blackboard*', ['work']),\n",
       "              ('blacke*', ['percept', 'see']),\n",
       "              ('blackish*', ['percept', 'see']),\n",
       "              ('blackjack', ['leisure']),\n",
       "              ('blacks', ['percept', 'see']),\n",
       "              ('bladder*', ['bio', 'body']),\n",
       "              ('blah', ['filler']),\n",
       "              ('blam*', ['social', 'affect', 'negemo', 'anger']),\n",
       "              ('blatant*', ['cogmech', 'certain']),\n",
       "              ('bldg*', ['work']),\n",
       "              ('bleed*', ['bio', 'health']),\n",
       "              ('blender*', ['home']),\n",
       "              ('bless*', ['affect', 'posemo', 'relig']),\n",
       "              ('blind*', ['bio', 'health', 'percept', 'see']),\n",
       "              ('block', ['cogmech', 'inhib']),\n",
       "              ('blockbuster*', ['leisure']),\n",
       "              ('blocked', ['cogmech', 'inhib']),\n",
       "              ('blocker*', ['cogmech', 'inhib']),\n",
       "              ('blocking', ['cogmech', 'inhib']),\n",
       "              ('blocks', ['cogmech', 'inhib']),\n",
       "              ('blog*', ['leisure']),\n",
       "              ('blond*', ['percept', 'see']),\n",
       "              ('blood', ['bio', 'body']),\n",
       "              ('bloody', ['bio', 'body', 'swear']),\n",
       "              ('blue*', ['percept', 'see']),\n",
       "              ('blur*', ['cogmech', 'tentat']),\n",
       "              ('bodi*', ['bio', 'body']),\n",
       "              ('body*', ['bio', 'body']),\n",
       "              ('boil*', ['bio', 'ingest']),\n",
       "              ('bold*', ['affect', 'posemo']),\n",
       "              ('bone', ['bio', 'body']),\n",
       "              ('boner*', ['bio', 'sexual']),\n",
       "              ('bones', ['bio', 'body']),\n",
       "              ('bonus*', ['affect', 'posemo', 'achieve', 'money']),\n",
       "              ('bony', ['bio', 'body']),\n",
       "              ('boob*', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('book*', ['work', 'leisure']),\n",
       "              ('boom*', ['percept', 'hear']),\n",
       "              ('booz*', ['bio', 'ingest']),\n",
       "              ('borderline*', ['cogmech', 'tentat']),\n",
       "              ('bore*', ['affect', 'negemo']),\n",
       "              ('boring', ['affect', 'negemo']),\n",
       "              ('born', ['time', 'relativ']),\n",
       "              ('borrow*', ['money']),\n",
       "              ('boss*', ['cogmech', 'cause', 'work']),\n",
       "              ('both',\n",
       "               ['funct', 'quant', 'cogmech', 'incl', 'space', 'relativ']),\n",
       "              ('bother*', ['affect', 'negemo', 'anger']),\n",
       "              ('bottom*', ['space', 'relativ']),\n",
       "              ('bought', ['verb', 'past', 'money']),\n",
       "              ('bound*', ['cogmech', 'inhib']),\n",
       "              ('bowel*', ['bio', 'body']),\n",
       "              ('boy', ['social', 'humans']),\n",
       "              (\"boy's\", ['social', 'humans']),\n",
       "              ('boyf*', ['social', 'friend']),\n",
       "              ('boys*', ['social', 'humans']),\n",
       "              ('brain*', ['bio', 'body']),\n",
       "              ('brake*', ['cogmech', 'inhib']),\n",
       "              ('brave*', ['affect', 'posemo']),\n",
       "              ('bread', ['bio', 'ingest']),\n",
       "              ('breadth', ['space', 'relativ']),\n",
       "              ('break', ['relativ']),\n",
       "              ('breakfast*', ['bio', 'ingest']),\n",
       "              ('breast*', ['bio', 'body', 'sexual']),\n",
       "              ('breath*', ['bio', 'body']),\n",
       "              ('bridle*', ['cogmech', 'inhib']),\n",
       "              ('brief*', ['motion', 'relativ']),\n",
       "              ('bright*', ['affect', 'posemo', 'percept', 'see']),\n",
       "              ('brillian*', ['affect', 'posemo']),\n",
       "              ('bring', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('bringing', ['motion', 'relativ']),\n",
       "              ('brings', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('brink', ['space', 'relativ']),\n",
       "              ('bro', ['social', 'family']),\n",
       "              ('broad*', ['space', 'relativ']),\n",
       "              ('broke', ['affect', 'negemo', 'sad']),\n",
       "              ('broker*', ['work', 'money']),\n",
       "              ('bronchi*', ['bio', 'health']),\n",
       "              ('broom*', ['home']),\n",
       "              ('bros', ['social', 'family']),\n",
       "              ('brother*', ['social', 'family']),\n",
       "              ('brought', ['verb', 'past', 'motion', 'relativ']),\n",
       "              ('brown*', ['percept', 'see']),\n",
       "              ('brunch*', ['bio', 'ingest']),\n",
       "              ('brush*', ['percept', 'feel']),\n",
       "              ('brutal*', ['affect', 'negemo', 'anger']),\n",
       "              ('buck', ['money']),\n",
       "              ('bucks', ['money']),\n",
       "              ('bud', ['social', 'friend']),\n",
       "              ('buddh*', ['relig']),\n",
       "              ('buddies*', ['social', 'friend']),\n",
       "              ('buddy*', ['social', 'friend']),\n",
       "              ('budget*', ['money']),\n",
       "              ('building', ['relativ']),\n",
       "              ('bulimi*', ['bio', 'health', 'ingest']),\n",
       "              ('bunch', ['funct', 'quant']),\n",
       "              ('burden*', ['affect', 'negemo']),\n",
       "              ('bureau*', ['work']),\n",
       "              ('burial*', ['death']),\n",
       "              ('buried', ['death']),\n",
       "              ('burnout*', ['work', 'achieve']),\n",
       "              ('burp*', ['bio', 'health']),\n",
       "              ('bury', ['death']),\n",
       "              ('business*', ['work', 'money']),\n",
       "              ('busy', ['relativ', 'time', 'work']),\n",
       "              ('but', ['funct', 'conj', 'cogmech', 'excl']),\n",
       "              ('butt', ['bio', 'body', 'sexual', 'swear']),\n",
       "              (\"butt's\", ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('butter*', ['percept']),\n",
       "              ('butts', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('buy*', ['money']),\n",
       "              ('by', ['funct', 'preps']),\n",
       "              ('bye', ['social', 'relativ', 'time']),\n",
       "              ('caf*', ['bio', 'ingest']),\n",
       "              ('calculus', ['work']),\n",
       "              ('call', ['social']),\n",
       "              ('called', ['verb', 'past', 'social']),\n",
       "              ('caller*', ['social']),\n",
       "              ('calling', ['social']),\n",
       "              ('calls', ['social']),\n",
       "              ('calm*', ['affect', 'posemo']),\n",
       "              ('came',\n",
       "               ['verb', 'past', 'cogmech', 'incl', 'motion', 'relativ']),\n",
       "              ('camping', ['leisure']),\n",
       "              ('campus*', ['work']),\n",
       "              ('can', ['verb', 'funct', 'auxverb', 'present']),\n",
       "              (\"can't\", ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('cancer*', ['bio', 'health']),\n",
       "              ('candie*', ['bio', 'ingest']),\n",
       "              ('candle*', ['percept', 'see']),\n",
       "              ('candy', ['bio', 'ingest']),\n",
       "              ('cannot', ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('cant', ['verb', 'funct', 'auxverb', 'present', 'negate']),\n",
       "              ('capab*', ['achieve']),\n",
       "              ('capacit*', ['space', 'relativ']),\n",
       "              ('captain', ['social']),\n",
       "              ('car', ['relativ', 'motion']),\n",
       "              ('caramel*', ['percept']),\n",
       "              ('cardia*', ['bio', 'health']),\n",
       "              ('cardio*', ['bio', 'health']),\n",
       "              ('cards', ['leisure']),\n",
       "              ('care', ['verb', 'present', 'affect', 'posemo']),\n",
       "              ('cared', ['verb', 'past', 'affect', 'posemo']),\n",
       "              ('career*', ['work']),\n",
       "              ('carefree', ['affect', 'posemo']),\n",
       "              ('careful*', ['affect', 'posemo', 'cogmech', 'inhib']),\n",
       "              ('careless*', ['affect', 'negemo']),\n",
       "              ('cares', ['verb', 'present', 'affect', 'posemo']),\n",
       "              ('caress*', ['percept', 'feel']),\n",
       "              ('caring', ['affect', 'posemo']),\n",
       "              ('carpet*', ['home']),\n",
       "              ('carried', ['verb', 'past', 'motion', 'relativ']),\n",
       "              ('carrier*', ['motion', 'relativ']),\n",
       "              ('carries', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('carry', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('carrying', ['motion', 'relativ']),\n",
       "              ('cash*', ['money']),\n",
       "              ('casino*', ['leisure', 'money']),\n",
       "              ('casket*', ['death']),\n",
       "              ('casual', ['affect', 'posemo', 'leisure']),\n",
       "              ('casually', ['affect', 'posemo']),\n",
       "              ('casualt*', ['death']),\n",
       "              ('catch', ['relativ', 'motion']),\n",
       "              ('categor*', ['cogmech', 'insight']),\n",
       "              ('catholic*', ['relig']),\n",
       "              ('caught', ['verb', 'past', 'relativ', 'motion']),\n",
       "              ('caus*', ['cogmech', 'cause']),\n",
       "              ('caut*', ['cogmech', 'inhib']),\n",
       "              ('cd*', ['leisure']),\n",
       "              ('cease*', ['cogmech', 'inhib', 'time', 'relativ']),\n",
       "              ('ceasing', ['cogmech', 'inhib', 'time', 'relativ']),\n",
       "              ('ceiling*', ['space', 'relativ']),\n",
       "              ('celebrat*', ['social', 'achieve', 'leisure']),\n",
       "              ('celebrit*', ['leisure']),\n",
       "              ('cell', ['social']),\n",
       "              ('cellphon*', ['social']),\n",
       "              ('cells', ['social']),\n",
       "              ('cellular*', ['social']),\n",
       "              ('cemet*', ['death']),\n",
       "              ('cent', ['money']),\n",
       "              ('center*', ['space', 'relativ']),\n",
       "              ('centre*', ['space', 'relativ']),\n",
       "              ('cents', ['money']),\n",
       "              ('centur*', ['time', 'relativ']),\n",
       "              ('ceo*', ['work']),\n",
       "              ('certain*', ['affect', 'posemo', 'cogmech', 'certain']),\n",
       "              ('certif*', ['work']),\n",
       "              ('cetera', ['funct', 'quant']),\n",
       "              ('chairm*', ['work']),\n",
       "              ('chalk', ['work']),\n",
       "              ('challeng*', ['affect', 'posemo', 'work', 'achieve']),\n",
       "              ('champ*', ['affect', 'posemo', 'work', 'achieve']),\n",
       "              ('chance', ['cogmech', 'tentat']),\n",
       "              ('change', ['relativ', 'motion', 'cogmech', 'cause']),\n",
       "              ('changed',\n",
       "               ['verb', 'past', 'relativ', 'motion', 'cogmech', 'cause']),\n",
       "              ('changes', ['relativ', 'motion', 'cogmech', 'cause']),\n",
       "              ('changing', ['relativ', 'motion', 'cogmech', 'cause']),\n",
       "              ('channel*', ['leisure']),\n",
       "              ('chapel*', ['relig']),\n",
       "              ('chaplain*', ['relig']),\n",
       "              ('charit*', ['affect', 'posemo', 'money']),\n",
       "              ('charm*', ['affect', 'posemo']),\n",
       "              ('chat*', ['social', 'leisure']),\n",
       "              ('cheap*', ['money']),\n",
       "              ('cheat*', ['affect', 'negemo', 'anger']),\n",
       "              ('check', ['money']),\n",
       "              ('checkers', ['leisure']),\n",
       "              ('checking', ['money']),\n",
       "              ('checks', ['money']),\n",
       "              ('checkup*', ['bio', 'health']),\n",
       "              ('cheek*', ['bio', 'body']),\n",
       "              ('cheer*', ['affect', 'posemo']),\n",
       "              ('chequ*', ['money']),\n",
       "              ('cherish*', ['affect', 'posemo']),\n",
       "              ('chess', ['leisure']),\n",
       "              ('chest*', ['bio', 'body']),\n",
       "              ('chew*', ['bio', 'ingest']),\n",
       "              ('chick', ['social', 'humans']),\n",
       "              (\"chick'*\", ['social', 'humans']),\n",
       "              ('child', ['social', 'humans']),\n",
       "              (\"child's\", ['social', 'humans']),\n",
       "              ('childhood', ['relativ', 'time']),\n",
       "              ('children*', ['social', 'humans']),\n",
       "              ('chillin*', ['leisure']),\n",
       "              ('chills', ['bio', 'health']),\n",
       "              ('chiropract*', ['bio', 'health']),\n",
       "              ('chlamydia', ['bio', 'health', 'sexual']),\n",
       "              ('chocolate*', ['percept']),\n",
       "              ('choice*', ['cogmech', 'insight']),\n",
       "              ('choir*', ['leisure', 'percept', 'hear']),\n",
       "              ('chok*', ['bio', 'health']),\n",
       "              ('cholester*', ['bio', 'health']),\n",
       "              ('choos*', ['cogmech', 'insight']),\n",
       "              ('chore*', ['home']),\n",
       "              ('chorus', ['leisure']),\n",
       "              ('chow*', ['bio', 'ingest']),\n",
       "              ('christ', ['relig']),\n",
       "              ('christian*', ['relig']),\n",
       "              ('christmas*', ['relativ', 'time', 'relig']),\n",
       "              ('chronic*', ['bio', 'health']),\n",
       "              ('chuckl*', ['affect', 'posemo']),\n",
       "              ('church*', ['relig']),\n",
       "              ('cigar*', ['bio', 'ingest']),\n",
       "              ('cinema*', ['leisure']),\n",
       "              ('circle', ['percept', 'see']),\n",
       "              ('citizen', ['social', 'humans']),\n",
       "              (\"citizen'*\", ['social', 'humans']),\n",
       "              ('citizens', ['social', 'humans']),\n",
       "              ('citrus*', ['percept']),\n",
       "              ('city', ['relativ', 'space']),\n",
       "              ('clarif*', ['cogmech', 'insight']),\n",
       "              ('class', ['work']),\n",
       "              ('classes', ['work']),\n",
       "              ('classmate*', ['work']),\n",
       "              ('classroom*', ['work']),\n",
       "              ('clean*', ['home']),\n",
       "              ('clear', ['cogmech', 'certain']),\n",
       "              ('clearly', ['funct', 'adverb', 'cogmech', 'certain']),\n",
       "              ('clergy', ['relig']),\n",
       "              ('clever*', ['affect', 'posemo']),\n",
       "              ('click*', ['percept', 'see']),\n",
       "              ('climb*', ['motion', 'relativ', 'achieve']),\n",
       "              ('clinic*', ['bio', 'health']),\n",
       "              ('clock*', ['time', 'relativ']),\n",
       "              ('close', ['cogmech', 'incl', 'space', 'relativ']),\n",
       "              ('closed', ['space', 'relativ']),\n",
       "              ('closely', ['motion', 'relativ']),\n",
       "              ('closer', ['space', 'relativ']),\n",
       "              ('closes', ['motion', 'relativ']),\n",
       "              ('closest', ['space', 'relativ']),\n",
       "              ('closet', ['home']),\n",
       "              ('closets', ['home']),\n",
       "              ('closing', ['motion', 'relativ']),\n",
       "              ('closure', ['cogmech', 'insight', 'achieve']),\n",
       "              ('clothes', ['bio', 'body']),\n",
       "              ('club*', ['leisure']),\n",
       "              ('coach*', ['leisure']),\n",
       "              ('cock', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('cocks*', ['bio', 'body', 'sexual', 'swear']),\n",
       "              ('cocktail*', ['bio', 'ingest', 'leisure']),\n",
       "              ('codeine', ['bio', 'health']),\n",
       "              ('coffee*', ['bio', 'ingest', 'leisure']),\n",
       "              ('coffin*', ['death']),\n",
       "              ('cohere*', ['cogmech', 'insight']),\n",
       "              ('coin', ['money']),\n",
       "              ('coins', ['money']),\n",
       "              ('coke*', ['bio', 'ingest']),\n",
       "              ('cold*', ['percept', 'feel']),\n",
       "              ('collab*', ['work']),\n",
       "              ('colleague*', ['social', 'friend', 'work']),\n",
       "              ('colleg*', ['work']),\n",
       "              ('cologne*', ['percept']),\n",
       "              ('colon', ['bio', 'body']),\n",
       "              ('colono*', ['bio', 'health']),\n",
       "              ('colons', ['bio', 'body']),\n",
       "              ('color*', ['percept', 'see']),\n",
       "              ('colour*', ['percept', 'see']),\n",
       "              ('column*', ['percept', 'see']),\n",
       "              ('com', ['work']),\n",
       "              ('coma*', ['bio', 'health']),\n",
       "              ('come',\n",
       "               ['verb', 'present', 'cogmech', 'incl', 'motion', 'relativ']),\n",
       "              ('comed*', ['affect', 'posemo', 'leisure']),\n",
       "              ('comes', ['verb', 'present', 'motion', 'relativ']),\n",
       "              ('comfort*', ['affect', 'posemo']),\n",
       "              ('comic*', ['leisure']),\n",
       "              ('coming', ['motion', 'relativ']),\n",
       "              ('comment*', ['social']),\n",
       "              ('commerc*', ['work']),\n",
       "              ('commit', ['cogmech', 'certain']),\n",
       "              ('commitment*', ['affect', 'posemo', 'cogmech', 'certain']),\n",
       "              ('commits', ['cogmech', 'certain']),\n",
       "              ('committ*', ['cogmech', 'certain']),\n",
       "              ('common', ['relativ', 'time']),\n",
       "              ('commun*', ['social']),\n",
       "              ('commute*', ['work']),\n",
       "              ('commuting', ['work']),\n",
       "              ('companies', ['work']),\n",
       "              ('companion', ['social', 'friend']),\n",
       "              ('companions', ['social', 'friend']),\n",
       "              ('companionship*', ['social']),\n",
       "              ('company', ['work']),\n",
       "              ('compassion*', ['social', 'affect', 'posemo']),\n",
       "              ('compel*', ['cogmech', 'cause']),\n",
       "              ('compensat*', ['money']),\n",
       "              ('compet*', ['achieve']),\n",
       "              ('complain*', ['social', 'affect', 'negemo']),\n",
       "              ('complete', ['cogmech', 'certain']),\n",
       "              ('completed', ['cogmech', 'certain']),\n",
       "              ('completely', ['funct', 'adverb', 'cogmech', 'certain']),\n",
       "              ('completes', ['cogmech', 'certain']),\n",
       "              ('complex*', ['cogmech', 'insight']),\n",
       "              ('compliance', ['cogmech', 'cause']),\n",
       "              ('complica*', ['cogmech', 'insight']),\n",
       "              ('complie*', ['cogmech', 'cause']),\n",
       "              ('compliment*', ['affect', 'posemo']),\n",
       "              ('comply*', ['cogmech', 'cause']),\n",
       "              ('compreh*', ['cogmech', 'insight']),\n",
       "              ('compulsiv*', ['cogmech', 'inhib']),\n",
       "              ('comput*', ['work']),\n",
       "              ('comrad*', ['social', 'friend']),\n",
       "              ('concentrat*', ['cogmech', 'insight']),\n",
       "              ('concerned', ['affect']),\n",
       "              ('concert*', ['leisure', 'percept', 'hear']),\n",
       "              ('conclud*', ['cogmech', 'insight', 'cause', 'achieve']),\n",
       "              ('conclus*', ['cogmech', 'insight', 'achieve']),\n",
       "              ('condo', ['home']),\n",
       "              ('condom', ['bio', 'sexual']),\n",
       "              ('condominium*', ['home']),\n",
       "              ('condoms', ['bio', 'sexual']),\n",
       "              ('condos', ['home']),\n",
       "              ('conferenc*', ['work']),\n",
       "              ('confess*', ['social', 'cogmech', 'insight', 'relig']),\n",
       "              ('confide', ['social']),\n",
       "              ('confided', ['social']),\n",
       "              ('confidence',\n",
       "               ['affect', 'posemo', 'cogmech', 'certain', 'achieve']),\n",
       "              ('confident',\n",
       "               ['affect', 'posemo', 'cogmech', 'certain', 'achieve']),\n",
       "              ('confidently',\n",
       "               ['affect', 'posemo', 'cogmech', 'certain', 'achieve']),\n",
       "              ('confides', ['social']),\n",
       "              ('confiding', ['social']),\n",
       "              ('confin*', ['cogmech', 'inhib']),\n",
       "              ('conflict*', ['cogmech', 'inhib']),\n",
       "              ('confront*', ['affect', 'negemo', 'anger']),\n",
       "              ('confus*', ['affect', 'negemo', 'anx', 'cogmech', 'tentat']),\n",
       "              ('congest*', ['bio', 'health']),\n",
       "              ('conglom*', ['work']),\n",
       "              ('congregat*', ['social']),\n",
       "              ('connection*', ['relativ', 'space']),\n",
       "              ('conquer*', ['achieve']),\n",
       "              ('conscientious*', ['achieve']),\n",
       "              ('conscious*', ['cogmech', 'insight']),\n",
       "              ('consequen*', ['cogmech', 'cause']),\n",
       "              ('conserv*', ['cogmech', 'inhib']),\n",
       "              ('consider', ['cogmech', 'insight']),\n",
       "              ('considerate', ['affect', 'posemo']),\n",
       "              ('considered', ['cogmech', 'insight']),\n",
       "              ('considering', ['cogmech', 'insight']),\n",
       "              ('considers', ['cogmech', 'insight']),\n",
       "              ('constant', ['relativ', 'time']),\n",
       "              ('constantly', ['funct', 'adverb', 'relativ', 'time']),\n",
       "              ('constipat*', ['bio', 'health']),\n",
       "              ('constrain*', ['cogmech', 'inhib']),\n",
       "              ('constrict*', ['cogmech', 'inhib']),\n",
       "              ('consult*', ['social', 'work']),\n",
       "              ('consumer*', ['work', 'money']),\n",
       "              ('contact*', ['social']),\n",
       "              ('contag*', ['bio', 'health']),\n",
       "              ('contain*', ['cogmech', 'inhib']),\n",
       "              ('contemplat*', ['cogmech', 'insight']),\n",
       "              ('contempt*', ['affect', 'negemo', 'anger']),\n",
       "              ('contented*', ['affect', 'posemo']),\n",
       "              ('contentment', ['affect', 'posemo']),\n",
       "              ('contingen*', ['cogmech', 'tentat']),\n",
       "              ('continu*', ['time', 'relativ']),\n",
       "              ('contracts', ['work']),\n",
       "              ('contradic*',\n",
       "               ['social', 'affect', 'negemo', 'anger', 'cogmech', 'inhib']),\n",
       "              ('control*', ['cogmech', 'cause', 'inhib', 'achieve']),\n",
       "              ('convent', ['relig']),\n",
       "              ('convents', ['relig']),\n",
       "              ('convers*', ['social']),\n",
       "              ('convinc*', ['affect', 'posemo']),\n",
       "              ('cook*', ['bio', 'ingest', 'leisure']),\n",
       "              ('cool', ['affect', 'posemo', 'assent', 'percept', 'feel']),\n",
       "              ('cornea*', ['bio', 'body']),\n",
       "              ('corner', ['space', 'relativ']),\n",
       "              ('corners', ['space', 'relativ']),\n",
       "              ('coronar*', ['bio', 'health']),\n",
       "              ('coroner*', ['death', 'death']),\n",
       "              ('corp', ['work']),\n",
       "              ('corporat*', ['work', 'money']),\n",
       "              ('corps', ['work']),\n",
       "              ('corpse*', ['death']),\n",
       "              ('correct*', ['cogmech', 'certain']),\n",
       "              ('correlat*', ['cogmech', 'insight']),\n",
       "              ('cos', ['cogmech', 'cause']),\n",
       "              ('cost*', ['money']),\n",
       "              ('couch*', ['home']),\n",
       "              ('cough*', ['bio', 'health']),\n",
       "              ('could', ['verb', 'funct', 'auxverb', 'cogmech', 'discrep']),\n",
       "              (\"could've\",\n",
       "               ['verb',\n",
       "                'funct',\n",
       "                'auxverb',\n",
       "                'past',\n",
       "                'future',\n",
       "                'cogmech',\n",
       "                'discrep']),\n",
       "              (\"couldn't\",\n",
       "               ['verb', 'funct', 'auxverb', 'negate', 'cogmech', 'discrep']),\n",
       "              ('couldnt',\n",
       "               ['verb', 'funct', 'auxverb', 'negate', 'cogmech', 'discrep']),\n",
       "              ('couldve',\n",
       "               ['verb',\n",
       "                'funct',\n",
       "                'auxverb',\n",
       "                'past',\n",
       "                'future',\n",
       "                'cogmech',\n",
       "                'discrep']),\n",
       "              ('counc*', ['social', 'work']),\n",
       "              ('couns*', ['social', 'work']),\n",
       "              ('countr*', ['relativ', 'space']),\n",
       "              ('couple', ['funct', 'quant']),\n",
       "              ('coupon*', ['money']),\n",
       "              ('courag*', ['affect', 'posemo']),\n",
       "              ('course*', ['work']),\n",
       "              ('cousin*', ['social', 'family']),\n",
       "              ('coverage', ['relativ', 'space']),\n",
       "              ('coworker*', ['social', 'work']),\n",
       "              ('coz', ['cogmech', 'cause']),\n",
       "              ('cramp*', ['bio', 'health']),\n",
       "              ('crap', ['affect', 'negemo', 'anger', 'bio', 'body', 'swear']),\n",
       "              ('crappy', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('craz*', ['affect', 'negemo', 'anx']),\n",
       "              ('cream', ['percept', 'see']),\n",
       "              ('create*', ['affect', 'posemo', 'cogmech', 'cause', 'achieve']),\n",
       "              ('creati*', ['affect', 'posemo', 'cogmech', 'cause', 'achieve']),\n",
       "              ('credential*', ['work']),\n",
       "              ('credit*', ['affect', 'posemo', 'work', 'money']),\n",
       "              ('cremat*', ['death']),\n",
       "              ('cried', ['verb', 'past', 'affect', 'negemo', 'sad']),\n",
       "              ('cries', ['affect', 'negemo', 'sad']),\n",
       "              ('critical', ['affect', 'negemo', 'anger']),\n",
       "              ('critici*', ['affect', 'negemo', 'anger']),\n",
       "              ('cross*', ['motion', 'relativ']),\n",
       "              ('crotch', ['bio', 'body']),\n",
       "              ('crowd*', ['social']),\n",
       "              ('crown*', ['achieve']),\n",
       "              ('crucifi*', ['relig']),\n",
       "              ('crude*', ['affect', 'negemo', 'anger']),\n",
       "              ('cruel*', ['affect', 'negemo', 'anger']),\n",
       "              ('cruis*', ['motion', 'relativ', 'leisure']),\n",
       "              ('crusade*', ['relig']),\n",
       "              ('crushed', ['affect', 'negemo', 'sad']),\n",
       "              ('cry', ['affect', 'negemo', 'sad']),\n",
       "              ('crying', ['affect', 'negemo', 'sad']),\n",
       "              ('crypt*', ['death']),\n",
       "              ('cubicle*', ['work']),\n",
       "              ('cuddl*', ['bio', 'sexual']),\n",
       "              ('cultur*', ['social']),\n",
       "              ('cunt*', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('curb*', ['cogmech', 'inhib']),\n",
       "              ('curio*', ['cogmech', 'insight']),\n",
       "              ('currenc*', ['money']),\n",
       "              ('current*', ['time', 'relativ']),\n",
       "              ('curricul*', ['work']),\n",
       "              ('curtail*', ['cogmech', 'inhib']),\n",
       "              ('curtain*', ['home']),\n",
       "              ('customer*', ['work', 'money']),\n",
       "              ('cut', ['affect', 'negemo', 'anger']),\n",
       "              ('cute*', ['affect', 'posemo']),\n",
       "              ('cutie*', ['affect', 'posemo']),\n",
       "              ('cuz', ['funct', 'conj', 'cogmech', 'cause']),\n",
       "              ('cv*', ['work']),\n",
       "              ('cycle*', ['time', 'relativ']),\n",
       "              ('cynic', ['affect', 'negemo', 'anger']),\n",
       "              ('cyst*', ['bio', 'health']),\n",
       "              ('dad*', ['social', 'family']),\n",
       "              ('dail*', ['time', 'relativ']),\n",
       "              ('damag*', ['affect', 'negemo', 'sad']),\n",
       "              ('damn*', ['affect', 'negemo', 'anger', 'swear']),\n",
       "              ('danc*', ['motion', 'relativ', 'leisure']),\n",
       "              ('dang', ['swear']),\n",
       "              ('danger*', ['affect', 'negemo', 'anger']),\n",
       "              ('daring', ['affect', 'posemo']),\n",
       "              ('darlin*', ['affect', 'posemo']),\n",
       "              ('darn', ['swear']),\n",
       "              ('date*', ['time', 'relativ']),\n",
       "              ('dating', ['social']),\n",
       "              ('daughter*', ['social', 'family']),\n",
       "              ('day*', ['time', 'relativ']),\n",
       "              ('daze*', ['affect', 'negemo']),\n",
       "              ('dead', ['death']),\n",
       "              ('deadline*', ['work']),\n",
       "              ('deaf*', ['bio', 'health', 'percept', 'hear']),\n",
       "              ('deal', ['social']),\n",
       "              ('dean*', ['work']),\n",
       "              ('dear*', ['affect', 'posemo']),\n",
       "              ('death*', ['death']),\n",
       "              ('debit*', ['money']),\n",
       "              ('debt*', ['money']),\n",
       "              ('decade*', ['time', 'relativ']),\n",
       "              ('decay*', ['affect', 'negemo', 'time', 'relativ']),\n",
       "              ('decease*', ['death']),\n",
       "              ('december', ['time', 'relativ']),\n",
       "              ('decid*', ['cogmech', 'insight']),\n",
       "              ('decis*', ['cogmech', 'insight']),\n",
       "              ('decongest*', ['bio', 'health']),\n",
       "              ('decorat*', ['leisure']),\n",
       "              ('deduc*', ['cogmech', 'insight', 'cause']),\n",
       "              ('deep*', ['space', 'relativ']),\n",
       "              ('defeat*', ['affect', 'negemo', 'sad', 'achieve']),\n",
       "              ('defect*', ['affect', 'negemo']),\n",
       "              ('defenc*', ['affect', 'negemo', 'anger', 'cogmech', 'inhib']),\n",
       "              ('defens*', ['affect', 'negemo', 'anger', 'cogmech', 'inhib']),\n",
       "              ('define', ['cogmech', 'insight']),\n",
       "              ('defined', ['cogmech', 'certain']),\n",
       "              ('defines', ['cogmech', 'insight']),\n",
       "              ('defining', ['cogmech', 'insight']),\n",
       "              ('definite', ['affect', 'posemo', 'cogmech', 'certain']),\n",
       "              ('definitely',\n",
       "               ['funct', 'adverb', 'affect', 'posemo', 'cogmech', 'certain']),\n",
       "              ('definitive*', ['cogmech', 'certain']),\n",
       "              ('degrad*', ['affect', 'negemo']),\n",
       "              ('delay*', ['cogmech', 'inhib', 'time', 'relativ']),\n",
       "              ('delectabl*', ['percept', 'affect', 'posemo']),\n",
       "              ('delegat*', ['work']),\n",
       "              ('delicate*', ['affect', 'posemo']),\n",
       "              ('delicious*', ['affect', 'posemo', 'percept']),\n",
       "              ('deligh*', ['affect', 'posemo']),\n",
       "              ('deliver*', ['motion', 'relativ']),\n",
       "              ('demise', ['death']),\n",
       "              ('demon*', ['relig']),\n",
       "              ('demote*', ['work']),\n",
       "              ('den', ['home']),\n",
       "              ('denia*', ['cogmech', 'inhib']),\n",
       "              ('denie*', ['cogmech', 'inhib']),\n",
       "              ('dense', ['space', 'relativ']),\n",
       "              ('densit*', ['space', 'relativ']),\n",
       "              ('dentist*', ['bio', 'health']),\n",
       "              ('deny*', ['cogmech', 'inhib']),\n",
       "              ('deoder*', ['percept']),\n",
       "              ('depart', ['motion', 'relativ']),\n",
       "              ('departed', ['motion', 'relativ']),\n",
       "              ('departing', ['motion', 'relativ']),\n",
       "              ('department*', ['work']),\n",
       "              ('departs', ['motion', 'relativ']),\n",
       "              ('departure*', ['motion', 'relativ']),\n",
       "              ('depend', ['cogmech', 'cause', 'tentat']),\n",
       "              ('depended', ['verb', 'past', 'cogmech', 'cause', 'tentat']),\n",
       "              ('depending', ['cogmech', 'cause', 'tentat']),\n",
       "              ('depends', ['verb', 'present', 'cogmech', 'cause', 'tentat']),\n",
       "              ('deposit*', ['money']),\n",
       "              ('depress*', ['affect', 'negemo', 'sad']),\n",
       "              ('depriv*', ['affect', 'negemo', 'sad']),\n",
       "              ('dept', ['work']),\n",
       "              ('depth*', ['space', 'relativ']),\n",
       "              ('derma*', ['bio', 'health']),\n",
       "              ('describe', ['verb', 'present', 'social']),\n",
       "              ('described', ['verb', 'past', 'social']),\n",
       "              ('describes', ['verb', 'present', 'social']),\n",
       "              ('describing', ['social']),\n",
       "              ('desir*', ['cogmech', 'discrep']),\n",
       "              ('desk*', ['work']),\n",
       "              ('despair*', ['affect', 'negemo', 'sad']),\n",
       "              ('desperat*', ['affect', 'negemo', 'anx']),\n",
       "              ('despis*', ['affect', 'negemo', 'anger']),\n",
       "              ('despite', ['funct', 'preps']),\n",
       "              ('dessert*', ['bio', 'ingest']),\n",
       "              ('destroy*', ['affect', 'negemo', 'anger']),\n",
       "              ('destruct*', ['affect', 'negemo', 'anger']),\n",
       "              ('determina*',\n",
       "               ['affect', 'posemo', 'cogmech', 'insight', 'achieve']),\n",
       "              ('determine', ['cogmech', 'insight']),\n",
       "              ('determined',\n",
       "               ['affect', 'posemo', 'cogmech', 'insight', 'achieve']),\n",
       "              ('determines', ['cogmech', 'insight']),\n",
       "              ('determining', ['cogmech', 'insight']),\n",
       "              ('detox*', ['bio', 'health']),\n",
       "              ('devastat*', ['affect', 'negemo', 'sad']),\n",
       "              ('devil*', ['affect', 'negemo', 'relig']),\n",
       "              ('devot*', ['affect', 'posemo']),\n",
       "              ('diabet*', ['bio', 'health']),\n",
       "              ('diagnos*', ['bio', 'health']),\n",
       "              ('diagonal*', ['space', 'relativ']),\n",
       "              ...]),\n",
       " odict_values([['funct'], ['pronoun'], ['ppron'], ['i'], ['we'], ['you'], ['shehe'], ['they'], ['ipron'], ['article'], ['verb'], ['auxverb'], ['past'], ['present'], ['future'], ['adverb'], ['preps'], ['conj'], ['negate'], ['quant'], ['number'], ['swear'], ['social'], ['family'], ['friend'], ['humans'], ['affect'], ['posemo'], ['negemo'], ['anx'], ['anger'], ['sad'], ['cogmech'], ['insight'], ['cause'], ['discrep'], ['tentat'], ['certain'], ['inhib'], ['incl'], ['excl'], ['percept'], ['see'], ['hear'], ['feel'], ['bio'], ['body'], ['health'], ['sexual'], ['ingest'], ['relativ'], ['motion'], ['space'], ['time'], ['work'], ['achieve'], ['leisure'], ['home'], ['money'], ['relig'], ['death'], ['assent'], ['nonfl'], ['filler']]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c4954e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_liwc = pd.DataFrame()\n",
    "for i in stories.index:\n",
    "    text = stories['text'][i]\n",
    "    liwc_counts = utils.wordCount(text, mydict)\n",
    "    liwc_df = pd.DataFrame(list(liwc_counts[0].items())).set_index(0) / liwc_counts[2]\n",
    "    liwc_df.columns = [stories.loc[i,'sid']]\n",
    "    stories_liwc = pd.concat([stories_liwc,liwc_df],axis=1)\n",
    "stories_liwc = stories_liwc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2bed07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_liwc = pd.merge(stories_hofstede,stories_liwc,right_index=True,left_on='sid').set_index('sid')\n",
    "nation_liwc = nation_liwc.groupby('nation').mean().reset_index()\n",
    "nation_liwc.columns\n",
    "hofstede_cols = ['pdi','idv','mas','uai','ltowvs','ivr']\n",
    "liwc_cols = nation_liwc.columns[8:]\n",
    "for col in liwc_cols:\n",
    "    nation_liwc[col] = (nation_liwc[col] - nation_liwc[col].mean())/nation_liwc[col].std()\n",
    "\n",
    "nation_liwc.to_csv(save_progress+\"nation_liwc.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b559d",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "731b7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_corpus = [models.doc2vec.TaggedDocument(words=l, tags=[str(i)]) for i, l in enumerate(lemmas)]\n",
    "# doc_model = models.doc2vec.Doc2Vec(doc_corpus, min_count=200, window=10, workers=8)\n",
    "# doc_model.save(save_progress+'doc2vec.model')\n",
    "# doc_model = models.doc2vec.Doc2Vec.load(save_progress+'doc2vec.model')\n",
    "# tsne = utils.doc2vec_tsne(doc_model, stories['language_family'])\n",
    "tsne = pd.merge(tsne, stories[['nation','language_family']], left_index=True, right_index=True, how='left')\n",
    "tsne = tsne.rename(columns={'nation':'Nation'})\n",
    "tsne['Nation'] = tsne['Nation'].str.title()\n",
    "tsne['language_family'] = tsne['language_family'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2c095b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.to_csv(save_progress+\"tsne.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "951516fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Nation</th>\n",
       "      <th>language_family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.040495</td>\n",
       "      <td>6.338946</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>East_Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.613154</td>\n",
       "      <td>23.311752</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.550614</td>\n",
       "      <td>-11.772786</td>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.067266</td>\n",
       "      <td>30.262329</td>\n",
       "      <td>French</td>\n",
       "      <td>Italic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.574621</td>\n",
       "      <td>33.876457</td>\n",
       "      <td>North_American_Native</td>\n",
       "      <td>Native_American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>-13.959932</td>\n",
       "      <td>22.061859</td>\n",
       "      <td>Australian_Ethnic</td>\n",
       "      <td>Austronesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>4.039639</td>\n",
       "      <td>13.369742</td>\n",
       "      <td>Scottish</td>\n",
       "      <td>Celtic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-17.184561</td>\n",
       "      <td>-11.282936</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Italic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>5.765532</td>\n",
       "      <td>-33.906895</td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>5.417030</td>\n",
       "      <td>4.717605</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>Uralic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1         X2                 Nation  language_family\n",
       "0    -17.040495   6.338946               Japanese        East_Asia\n",
       "1     -1.613154  23.311752                Serbian           Slavic\n",
       "2     -7.550614 -11.772786                 German         Germanic\n",
       "3     28.067266  30.262329                 French           Italic\n",
       "4    -18.574621  33.876457  North_American_Native  Native_American\n",
       "...         ...        ...                    ...              ...\n",
       "2927 -13.959932  22.061859      Australian_Ethnic     Austronesian\n",
       "2928   4.039639  13.369742               Scottish           Celtic\n",
       "2929 -17.184561 -11.282936                Italian           Italic\n",
       "2930   5.765532 -33.906895              Norwegian         Germanic\n",
       "2931   5.417030   4.717605                Finnish           Uralic\n",
       "\n",
       "[2932 rows x 4 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6535b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca20 = utils.doc2vec_tsne(doc_model, stories['language_family'], 20)\n",
    "pca20 = pd.merge(pca20, stories[['nation','language_family']], left_index=True, right_index=True, how='left')\n",
    "pca20 = pca20.rename(columns={'nation':'Nation'})\n",
    "pca20['Nation'] = pca20['Nation'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1ade0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vals = utils.doc2vec_tsne(doc_model, stories['language_family'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b661b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.040495 ,   6.3389463],\n",
       "       [ -1.613154 ,  23.311752 ],\n",
       "       [ -7.5506144, -11.772786 ],\n",
       "       ...,\n",
       "       [-17.18456  , -11.282936 ],\n",
       "       [  5.7655325, -33.906895 ],\n",
       "       [  5.4170303,   4.7176046]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f996109",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceddd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(lemmas.sample(frac=0.5))\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in lemmas]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "920ab7bd2fb7bd74b8de78632b6a92fbd66bc8d5dac803b94bc0f9d7f61a3b48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
