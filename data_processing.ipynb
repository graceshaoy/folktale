{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ada4ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Counter in c:\\users\\grace\\anaconda3\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\grace\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c63d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grace\\anaconda3\\envs\\macs40400\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "\n",
    "import regex as re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora, models\n",
    "# from transformers import pipeline\n",
    "import string\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# import liwc\n",
    "import collections\n",
    "\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# from transformers import BertModel\n",
    "# from transformers import AutoTokenizer\n",
    "# from transformers import pipeline\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "save_progress = \"save_progress/\"\n",
    "data = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b186f6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\grace\\\\Desktop\\\\macs_404_patterns\\\\folktales\\\\utils.py'>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bfb752",
   "metadata": {},
   "source": [
    "# Processing story data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6ad5967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = pd.read_csv(data+'folk_tales_deduplicated.csv')\n",
    "stories = stories[['nation','title','text']]\n",
    "stories = stories.dropna(subset = ['nation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578202e",
   "metadata": {},
   "source": [
    "### Getting lemmas/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5bdb029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [utils.to_wordlist([stories.text[x]]) for x in stories.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "37da82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_bystory = []\n",
    "for story in wordlist:\n",
    "    wordlist_bystory.append([word for chunk in story for word in chunk])\n",
    "stories['wordlist'] = wordlist_bystory\n",
    "stories['cleaned'] = [\" \".join(stories.wordlist[i]).replace(\"-\",\" \") for i in stories.index]\n",
    "stories['cleaned'] = [re.sub('[^a-zA-Z ]','',x) for x in stories.cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "823b678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stories.loc[stories['cleaned'].str.contains(' thor ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cafbd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmas = stories['cleaned'].apply(utils.get_lemmas)\n",
    "# lemmas.to_pickle(save_progress+'story_lemmas.pkl')\n",
    "lemmas = pd.read_pickle(save_progress+'story_lemmas.pkl')\n",
    "# stories['lemmas'] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6ae27023",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrased = utils.make_bigrams(lemmas)\n",
    "stories['phrased'] = phrased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd75f18",
   "metadata": {},
   "source": [
    "### Getting language families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1ee1ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data+\"grouped_regions.json\") as f:\n",
    "    grouped_regions = json.load(f)\n",
    "\n",
    "lang_fam = []\n",
    "for i in stories.index:\n",
    "    hasfam = False\n",
    "    for key in grouped_regions.keys():\n",
    "        if stories.loc[i,'nation'] in grouped_regions[key]:\n",
    "            lang_fam.append(key)\n",
    "            hasfam = True\n",
    "    if not hasfam:\n",
    "        lang_fam.append(np.nan)\n",
    "stories['language_family'] = lang_fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03ff0e",
   "metadata": {},
   "source": [
    "### Saving/reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "64460b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories['sid'] = stories.index\n",
    "stories['sid'] = stories['sid'].apply(lambda x: 'sid'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6c918720",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.to_csv(save_progress+'stories.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39de3bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nation</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wordlist</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>phrased</th>\n",
       "      <th>language_family</th>\n",
       "      <th>sid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>japanese</td>\n",
       "      <td>Momotaro</td>\n",
       "      <td>If you’ll believe me there was a time when the...</td>\n",
       "      <td>['believe', 'time', 'fairies', 'none', 'shy', ...</td>\n",
       "      <td>believe time fairies none shy time beasts talk...</td>\n",
       "      <td>['believe', 'time', 'fairy', 'none', 'time', '...</td>\n",
       "      <td>['believe', 'time', 'fairy', 'none', 'time', '...</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>sid0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>serbian</td>\n",
       "      <td>The Birdcatcher</td>\n",
       "      <td>Near Constantinople there lived a man who knew...</td>\n",
       "      <td>['near', 'constantinople', 'lived', 'man', 'kn...</td>\n",
       "      <td>near constantinople lived man knew occupation ...</td>\n",
       "      <td>['near', 'constantinople', 'live', 'knew', 'oc...</td>\n",
       "      <td>['near', 'constantinople', 'live', 'knew', 'oc...</td>\n",
       "      <td>slavic</td>\n",
       "      <td>sid1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     nation            title  \\\n",
       "0  japanese         Momotaro   \n",
       "1   serbian  The Birdcatcher   \n",
       "\n",
       "                                                text  \\\n",
       "0  If you’ll believe me there was a time when the...   \n",
       "1  Near Constantinople there lived a man who knew...   \n",
       "\n",
       "                                            wordlist  \\\n",
       "0  ['believe', 'time', 'fairies', 'none', 'shy', ...   \n",
       "1  ['near', 'constantinople', 'lived', 'man', 'kn...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  believe time fairies none shy time beasts talk...   \n",
       "1  near constantinople lived man knew occupation ...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  ['believe', 'time', 'fairy', 'none', 'time', '...   \n",
       "1  ['near', 'constantinople', 'live', 'knew', 'oc...   \n",
       "\n",
       "                                             phrased language_family   sid  \n",
       "0  ['believe', 'time', 'fairy', 'none', 'time', '...       east_asia  sid0  \n",
       "1  ['near', 'constantinople', 'live', 'knew', 'oc...          slavic  sid1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories = pd.read_csv(save_progress+'stories.csv')\n",
    "sid_nation = {}\n",
    "for i in stories.index:\n",
    "    sid_nation[stories['sid'][i]] = stories['nation'][i]\n",
    "nation_sid = {}\n",
    "for nation in stories.nation.unique():\n",
    "    nation_sid[nation] = list(stories.query('nation == @nation')['sid'])\n",
    "stories.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e41d0",
   "metadata": {},
   "source": [
    "## Processing Hofstede data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "20910d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hofstede = pd.read_excel(data+'hofstede.xlsx') # https://www.kaggle.com/datasets/aleksakenjic/hofstedes-cultural-dimensions\n",
    "language = pd.read_csv(data+'countries_languages.csv') # https://www.kaggle.com/datasets/shubhamptrivedi/languages-spoken-across-various-nations\n",
    "language['main'] = language['Languages Spoken'].apply(lambda x: x.split(' ')[0].replace(',','').split('/')[0])\n",
    "hofstede = pd.merge(hofstede,language[['Country','main']],how='left',left_on='country',right_on='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b37cded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ctr</th>\n",
       "      <th>country</th>\n",
       "      <th>pdi</th>\n",
       "      <th>idv</th>\n",
       "      <th>mas</th>\n",
       "      <th>uai</th>\n",
       "      <th>ltowvs</th>\n",
       "      <th>ivr</th>\n",
       "      <th>estim</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Country</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOS</td>\n",
       "      <td>Bosnia</td>\n",
       "      <td>90</td>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>87</td>\n",
       "      <td>69.773300</td>\n",
       "      <td>44.196429</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CZE</td>\n",
       "      <td>Czech Rep</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>70.025189</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DOM</td>\n",
       "      <td>Dominican Rep</td>\n",
       "      <td>65</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>13.098237</td>\n",
       "      <td>54.241071</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HOK</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>68</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "      <td>29</td>\n",
       "      <td>60.957179</td>\n",
       "      <td>16.964286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>KOR</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>85</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>MAC</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>90</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>87</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>PUE</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.955357</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>STP</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SLK</td>\n",
       "      <td>Slovak Rep</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>51</td>\n",
       "      <td>76.574307</td>\n",
       "      <td>28.348214</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>USA</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>40</td>\n",
       "      <td>91</td>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>25.692695</td>\n",
       "      <td>68.080357</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ctr                country  pdi  idv  mas  uai      ltowvs        ivr  \\\n",
       "11  BOS                 Bosnia   90   22   48   87   69.773300  44.196429   \n",
       "21  CZE              Czech Rep   57   58   57   74   70.025189  29.464286   \n",
       "23  DOM          Dominican Rep   65   30   65   45   13.098237  54.241071   \n",
       "34  HOK              Hong Kong   68   25   57   29   60.957179  16.964286   \n",
       "46  KOR            South Korea   60   18   39   85  100.000000  29.464286   \n",
       "62  MAC        North Macedonia   90   22   45   87   62.000000  35.000000   \n",
       "70  PUE            Puerto Rico   68   27   56   38    0.000000  89.955357   \n",
       "73  STP  Sao Tome and Principe   75   37   24   70   32.000000  41.000000   \n",
       "77  SLK             Slovak Rep  100   52  110   51   76.574307  28.348214   \n",
       "89  USA                 U.S.A.   40   91   62   46   25.692695  68.080357   \n",
       "\n",
       "    estim  Unnamed: 9 Unnamed: 10 Country main  \n",
       "11      1         NaN         NaN     NaN  NaN  \n",
       "21      0         NaN         NaN     NaN  NaN  \n",
       "23      1         NaN         NaN     NaN  NaN  \n",
       "34      0         NaN         NaN     NaN  NaN  \n",
       "46      0         NaN         NaN     NaN  NaN  \n",
       "62      1         NaN         NaN     NaN  NaN  \n",
       "70      1         NaN         NaN     NaN  NaN  \n",
       "73      1         NaN         NaN     NaN  NaN  \n",
       "77      0         NaN         NaN     NaN  NaN  \n",
       "89      0         NaN         NaN     NaN  NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hofstede[hofstede['main'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "7d5ad6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hofstede_fillna = {'Bosnia':'bosnian','Czech Rep':'czechoslovak','South Korea':'korean','U.S.A':'English'}\n",
    "hofstede['main'] = hofstede['main'].apply(lambda x: hofstede_fillna[x] if x in hofstede_fillna.keys() else x)\n",
    "hofstede = hofstede.groupby('main').mean().reset_index()\n",
    "hofstede['main'] = hofstede['main'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "3d4f26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_hofstede = pd.merge(stories[['sid','nation','language_family','title','text']], hofstede[['pdi','idv','mas','uai','ltowvs','ivr','main']], left_on='nation', right_on='main', how='inner').drop(columns='main')\n",
    "stories_hofstede.to_csv(save_progress+'stories_hofstede.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b5f9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>nation</th>\n",
       "      <th>language_family</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>pdi</th>\n",
       "      <th>idv</th>\n",
       "      <th>mas</th>\n",
       "      <th>uai</th>\n",
       "      <th>ltowvs</th>\n",
       "      <th>ivr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sid0</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>Momotaro</td>\n",
       "      <td>If you’ll believe me there was a time when the...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sid65</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Filial Girl</td>\n",
       "      <td>A girl once lived in the province of Echigo, w...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sid109</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Tongue-Cut Sparrow</td>\n",
       "      <td>Once upon a time there was an old man who live...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sid122</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>The Mallet</td>\n",
       "      <td>There were once two farmer men who were brothe...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sid210</td>\n",
       "      <td>japanese</td>\n",
       "      <td>east_asia</td>\n",
       "      <td>Karma</td>\n",
       "      <td>The young man, Ito Tatewaki, was returning hom...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.90932</td>\n",
       "      <td>41.741071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sid    nation language_family                   title  \\\n",
       "0    sid0  japanese       east_asia                Momotaro   \n",
       "1   sid65  japanese       east_asia         The Filial Girl   \n",
       "2  sid109  japanese       east_asia  The Tongue-Cut Sparrow   \n",
       "3  sid122  japanese       east_asia              The Mallet   \n",
       "4  sid210  japanese       east_asia                   Karma   \n",
       "\n",
       "                                                text   pdi   idv   mas   uai  \\\n",
       "0  If you’ll believe me there was a time when the...  54.0  46.0  95.0  92.0   \n",
       "1  A girl once lived in the province of Echigo, w...  54.0  46.0  95.0  92.0   \n",
       "2  Once upon a time there was an old man who live...  54.0  46.0  95.0  92.0   \n",
       "3  There were once two farmer men who were brothe...  54.0  46.0  95.0  92.0   \n",
       "4  The young man, Ito Tatewaki, was returning hom...  54.0  46.0  95.0  92.0   \n",
       "\n",
       "     ltowvs        ivr  \n",
       "0  87.90932  41.741071  \n",
       "1  87.90932  41.741071  \n",
       "2  87.90932  41.741071  \n",
       "3  87.90932  41.741071  \n",
       "4  87.90932  41.741071  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_hofstede = pd.read_csv(save_progress+'stories_hofstede.csv')\n",
    "stories_hofstede.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc3c6f",
   "metadata": {},
   "source": [
    "# Lemma Frequencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29cd78a7",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92181bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_counts = utils.make_posdict(lemma_counts,'n')\n",
    "verb_counts = utils.make_posdict(lemma_counts,'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f1172c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bynation = utils.group_lemmacounts_bynation(noun_counts,list(stories.nation.unique())).to_csv(save_progress+\"nouns_bynation.csv\",index=True)\n",
    "nouns_bynation = pd.read_csv(save_progress+\"nouns_bynation.csv\",index_col=0)\n",
    "# verbs_bynation = utils.group_lemmacounts_bynation(verb_counts,list(stories.nation.unique())).to_csv(save_progress+\"verbs_bynation.csv\",index=True)\n",
    "# verbs_bynation = pd.read_csv(save_progress+\"verbs_bynation.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1a15f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bylangfam = nouns_bynation.T.copy().reset_index().rename(columns={'index':'Nation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "68eb8e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_bylangfam.loc[0,'Nation'] in grouped_regions[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e7004fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bylangfam = nouns_bynation.T.copy().reset_index().rename(columns={'index':'Nation'})\n",
    "lang_fam = []\n",
    "for i in nouns_bylangfam.index:\n",
    "    hasfam = False\n",
    "    for key in grouped_regions.keys():\n",
    "        if nouns_bylangfam.loc[i,'Nation'] in grouped_regions[key]:\n",
    "            lang_fam.append(key)\n",
    "            hasfam = True\n",
    "    if not hasfam:\n",
    "        lang_fam.append(np.nan)\n",
    "nouns_bylangfam['language_family'] = lang_fam\n",
    "nouns_bylangfam = nouns_bylangfam.groupby('language_family').mean().T\n",
    "nouns_bylangfam.to_csv(save_progress+\"nouns_bylangfam.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6e200b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>language_family</th>\n",
       "      <th>albanian</th>\n",
       "      <th>armenic</th>\n",
       "      <th>austronesian</th>\n",
       "      <th>bantu</th>\n",
       "      <th>celtic</th>\n",
       "      <th>chadic</th>\n",
       "      <th>east_asia</th>\n",
       "      <th>germanic</th>\n",
       "      <th>hellenic</th>\n",
       "      <th>hindustani</th>\n",
       "      <th>italic</th>\n",
       "      <th>native_american</th>\n",
       "      <th>native_cana</th>\n",
       "      <th>semitic</th>\n",
       "      <th>slavic</th>\n",
       "      <th>turkic</th>\n",
       "      <th>uralic</th>\n",
       "      <th>urgic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005725</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>princess</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mother</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.003310</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narran</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wyah</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mahthi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humpy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eagle_hawk</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5066 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "language_family  albanian  armenic  austronesian  bantu    celtic  chadic  \\\n",
       "lemma                                                                       \n",
       "king                  0.0      0.0      0.000740    0.0  0.004363     0.0   \n",
       "would                 0.0      0.0      0.004792    0.0  0.004861     0.0   \n",
       "princess              0.0      0.0      0.000296    0.0  0.001545     0.0   \n",
       "could                 0.0      0.0      0.003274    0.0  0.003762     0.0   \n",
       "mother                0.0      0.0      0.001989    0.0  0.001304     0.0   \n",
       "...                   ...      ...           ...    ...       ...     ...   \n",
       "narran                0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "wyah                  0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "mahthi                0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "humpy                 0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "eagle_hawk            0.0      0.0      0.000140    0.0  0.000000     0.0   \n",
       "\n",
       "language_family  east_asia  germanic  hellenic  hindustani    italic  \\\n",
       "lemma                                                                  \n",
       "king              0.002551  0.003541  0.009419    0.008664  0.004108   \n",
       "would             0.005725  0.004836  0.007731    0.005062  0.002462   \n",
       "princess          0.001751  0.001408  0.002133    0.002406  0.002019   \n",
       "could             0.004391  0.004301  0.006798    0.003195  0.001771   \n",
       "mother            0.002587  0.001709  0.003310    0.001660  0.000754   \n",
       "...                    ...       ...       ...         ...       ...   \n",
       "narran            0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "wyah              0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "mahthi            0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "humpy             0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "eagle_hawk        0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "language_family  native_american  native_cana  semitic    slavic  turkic  \\\n",
       "lemma                                                                      \n",
       "king                    0.001221          0.0      0.0  0.003378     0.0   \n",
       "would                   0.007762          0.0      0.0  0.002480     0.0   \n",
       "princess                0.000000          0.0      0.0  0.002368     0.0   \n",
       "could                   0.005866          0.0      0.0  0.001914     0.0   \n",
       "mother                  0.002365          0.0      0.0  0.001464     0.0   \n",
       "...                          ...          ...      ...       ...     ...   \n",
       "narran                  0.000000          0.0      0.0  0.000000     0.0   \n",
       "wyah                    0.000000          0.0      0.0  0.000000     0.0   \n",
       "mahthi                  0.000000          0.0      0.0  0.000000     0.0   \n",
       "humpy                   0.000000          0.0      0.0  0.000000     0.0   \n",
       "eagle_hawk              0.000000          0.0      0.0  0.000000     0.0   \n",
       "\n",
       "language_family  uralic  urgic  \n",
       "lemma                           \n",
       "king                0.0    0.0  \n",
       "would               0.0    0.0  \n",
       "princess            0.0    0.0  \n",
       "could               0.0    0.0  \n",
       "mother              0.0    0.0  \n",
       "...                 ...    ...  \n",
       "narran              0.0    0.0  \n",
       "wyah                0.0    0.0  \n",
       "mahthi              0.0    0.0  \n",
       "humpy               0.0    0.0  \n",
       "eagle_hawk          0.0    0.0  \n",
       "\n",
       "[5066 rows x 18 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_bylangfam.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_bynation = pd.read_csv(save_progress+\"nouns_bynation.csv\",index_col=0)\n",
    "# verbs_bynation = pd.read_csv(save_progress+\"verbs_bynation.csv\",index_col=0)\n",
    "nouns_bylangfam = pd.read_csv(save_progress+\"nouns_bylangfam.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a200da7",
   "metadata": {},
   "source": [
    "## % of stories that mention x lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d47c61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacount = pd.DataFrame()\n",
    "for i in stories.index:\n",
    "    lemma_count = pd.DataFrame(pd.Series(stories.iloc[i]['phrased'].strip(\"[]\").replace('\\'',\"\").split(\", \")).value_counts())\n",
    "    lemma_count.columns = ['sid'+str(i)]\n",
    "    stories_lemmacount = pd.merge(stories_lemmacount,lemma_count,left_index=True,right_index=True,how=\"outer\")\n",
    "stories_lemmacount = stories_lemmacount.fillna(0)\n",
    "\n",
    "stories_lemmacount = stories_lemmacount.reset_index()\n",
    "stories_lemmacount = stories_lemmacount.rename(columns={'index':'lemma'})\n",
    "stories_lemmacount = stories_lemmacount.set_index('lemma')\n",
    "stories_lemmacount.to_csv(save_progress+\"stories_lemmacount.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9820f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacount = pd.read_csv(save_progress+\"stories_lemmacount.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "96672071",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmacountT = stories_lemmacount.copy().T.reset_index()\n",
    "stories_lemmacountT = stories_lemmacountT.rename(columns={'level_0':'sid'})\n",
    "stories_lemmacountT = stories_lemmacountT.set_index('sid')\n",
    "stories_lemmacountT = pd.merge(stories_lemmacountT,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "stories_lemmacountT = stories_lemmacountT.rename(columns = {'nation_y':'nation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3e793c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sid0', 'sid2184', 'sid2577'], dtype='object')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_lemmacount.columns[np.where(stories_lemmacount.loc['momotaro']!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c7389629",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_storycount = dict(stories.groupby('nation').count()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8fd662f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = pd.read_csv(data+'bigrams.csv').set_index('bigram').rename(columns={' count':'count'})\n",
    "bigrams['count'] = bigrams['count'] + 0.00001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "826e876b",
   "metadata": {},
   "source": [
    "## percentile of group in lemma usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7fb31",
   "metadata": {},
   "source": [
    "count(lemma) / len(story words) --> avg freq --> percentile of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bf1a6",
   "metadata": {},
   "source": [
    "\"nation a is in the top n% of users of lemma x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "94161c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_lemmafreq = stories_lemmacount.copy()\n",
    "stories_lemmafreq = stories_lemmafreq.div(stories_lemmacount.sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "24acadb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid0</th>\n",
       "      <th>sid2184</th>\n",
       "      <th>sid2577</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aalborg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aard</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aarhus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aasvo</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuur</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuya</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuyder</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuyderzee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwanzigers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33763 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sid0  sid2184  sid2577\n",
       "lemma                             \n",
       "aalborg      0.0      0.0      0.0\n",
       "aard         0.0      0.0      0.0\n",
       "aarhus       0.0      0.0      0.0\n",
       "aaron        0.0      0.0      0.0\n",
       "aasvo        0.0      0.0      0.0\n",
       "...          ...      ...      ...\n",
       "zuur         0.0      0.0      0.0\n",
       "zuya         0.0      0.0      0.0\n",
       "zuyder       0.0      0.0      0.0\n",
       "zuyderzee    0.0      0.0      0.0\n",
       "zwanzigers   0.0      0.0      0.0\n",
       "\n",
       "[33763 rows x 3 columns]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_lemmafreq[stories_lemmafreq.columns[np.where(stories_lemmafreq.loc['momotaro']!=0)[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "6af3d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *! groupby\n",
    "groupby = 'nation' # nation, language_family\n",
    "wrt = 'nation' # nation/language_family, lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "e0731663",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemmamean = pd.merge(stories_lemmafreq.T,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "nation_lemmamean = nation_lemmamean.rename(columns={'nation_y':'nation'})\n",
    "nation_lemmamean = nation_lemmamean.groupby(groupby).mean()\n",
    "nation_lemmameanT= nation_lemmamean.T\n",
    "\n",
    "nation_lemmamean_save = nation_lemmameanT\n",
    "nation_lemmamean_save['englishness'] = lemma_englishness\n",
    "nation_lemmamean_save['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)\n",
    "nation_lemmamean_save.to_csv(save_progress+'nation_lemmamean.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "26fea9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_percentile = pd.DataFrame()\n",
    "if wrt == 'nation' or wrt == 'language_family':\n",
    "    for col in nation_lemmameanT:\n",
    "        lemma_percentile[col] = [percentileofscore(nation_lemmameanT[col], value) for value in nation_lemmameanT[col]]\n",
    "elif wrt == 'lemma':\n",
    "    for col in nation_lemmamean:\n",
    "        lemma_percentile[col] = [percentileofscore(nation_lemmamean[col], value) for value in nation_lemmamean[col]]\n",
    "    lemma_percentile = lemma_percentile.T\n",
    "lemma_percentile.columns = list(nation_lemmamean.index.values)\n",
    "# lemma_percentile['englishness'] = lemma_englishness\n",
    "# lemma_percentile['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)\n",
    "lemma_percentile = lemma_percentile.rename(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "cdd7f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile['englishness'] = lemma_englishness\n",
    "nation_lemma_lemmapercentile['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "4ac5750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile.to_csv(save_progress+\"nation_lemma_lemmapercentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7c10f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_percentile.to_csv(save_progress+f\"{groupby}_lemma_{wrt}percentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c12c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_lemma_lemmapercentile = pd.read_csv(save_progress+\"nation_lemma_lemmapercentile.csv\",index_col=0)\n",
    "nation_lemma_nationpercentile = pd.read_csv(save_progress+\"nation_lemma_nationpercentile.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003cad1",
   "metadata": {},
   "source": [
    "uniqueness to group = langfam/nation percentile <br>\n",
    "uniqueness within group = lemma percentile <br>\n",
    "<br>\n",
    "lemma_uniquness = unique1 x unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "1fbad35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation = pd.DataFrame(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))\n",
    "for col in nation_lemma_lemmapercentile.columns:\n",
    "    lemma_unique_nation[col] = nation_lemma_lemmapercentile[col].values+.5*nation_lemma_nationpercentile[col].values\n",
    "lemma_unique_nation = lemma_unique_nation.rename(index=dict(zip(range(len(list(nation_lemmamean.columns.values))),list(nation_lemmamean.columns.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "9a23aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation['englishness'] = lemma_englishness\n",
    "lemma_unique_nation['common'] = nation_lemmamentions[stories.nation.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "8f7b4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_unique_nation.to_csv(save_progress+'lemma_unique_nation.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b9de2e",
   "metadata": {},
   "source": [
    "### language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1b0205b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile = pd.merge(stories_lemmafreq.T,stories[['sid','nation','language_family']],left_index=True,right_on='sid')\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.rename(columns={'nation_y':'nation'})\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.groupby('language_family').mean()\n",
    "for col in langfam_lemmapercentile:\n",
    "    langfam_lemmapercentile[col] = [percentileofscore(langfam_lemmapercentile[col], value) for value in langfam_lemmapercentile[col]]\n",
    "langfam_lemmapercentile = langfam_lemmapercentile.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "23663127",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile['englishness'] = lemma_englishness\n",
    "langfam_lemmapercentile['common'] = langfam_lemmapercentile[stories.language_family.unique()].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8200121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfam_lemmapercentile.to_csv(save_progress+\"langfam_lemmapercentile.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "611cc5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>albanian</th>\n",
       "      <th>armenic</th>\n",
       "      <th>austronesian</th>\n",
       "      <th>bantu</th>\n",
       "      <th>celtic</th>\n",
       "      <th>chadic</th>\n",
       "      <th>east_asia</th>\n",
       "      <th>germanic</th>\n",
       "      <th>hellenic</th>\n",
       "      <th>hindustani</th>\n",
       "      <th>italic</th>\n",
       "      <th>native_american</th>\n",
       "      <th>native_cana</th>\n",
       "      <th>semitic</th>\n",
       "      <th>slavic</th>\n",
       "      <th>turkic</th>\n",
       "      <th>uralic</th>\n",
       "      <th>urgic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aalborg</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aard</th>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>100.0</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          albanian    armenic  austronesian  bantu     celtic     chadic  \\\n",
       "aalborg  50.000000  50.000000     50.000000   50.0  50.000000  50.000000   \n",
       "aard     44.444444  44.444444     94.444444  100.0  44.444444  44.444444   \n",
       "\n",
       "          east_asia   germanic   hellenic  hindustani     italic  \\\n",
       "aalborg  100.000000  50.000000  50.000000   50.000000  50.000000   \n",
       "aard      88.888889  44.444444  44.444444   44.444444  44.444444   \n",
       "\n",
       "         native_american  native_cana    semitic     slavic     turkic  \\\n",
       "aalborg        50.000000    50.000000  50.000000  50.000000  50.000000   \n",
       "aard           44.444444    44.444444  44.444444  44.444444  44.444444   \n",
       "\n",
       "            uralic      urgic  \n",
       "aalborg  50.000000  50.000000  \n",
       "aard     44.444444  44.444444  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfam_lemmapercentile = pd.read_csv(save_progress+\"langfam_lemmapercentile.csv\",index_col=0)\n",
    "langfam_lemmapercentile.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434baf26",
   "metadata": {},
   "source": [
    "# LIWC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "581f3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict = utils.readDict(data+'LIWC2007_English100131.dic')\n",
    "# power = ['king','queen','prince','princess','servant','master','lord','throne','emperor','palace','sultan','royal','majesty','tsar']\n",
    "royalty = ['king*','queen*','prince*','princess*','servant*','master*','lord*','throne*','emperor*','palace*','sultan*','royal*','majesty*','tsar*']\n",
    "hero = ['hero*','warrior*','knight*','beast*','brave*','courage*']\n",
    "edited_dict = liwc_dict[0].copy()\n",
    "for word in power:\n",
    "    if word in edited_dict.keys():\n",
    "        edited_dict[word] += ['power']\n",
    "    else:\n",
    "        edited_dict[word] = ['power']\n",
    "for word in royalty:\n",
    "    if word in edited_dict.keys():\n",
    "        edited_dict[word] += ['royalty']\n",
    "    else:\n",
    "        edited_dict[word] = ['royalty']\n",
    "for word in hero:\n",
    "    if word in edited_dict.keys():\n",
    "        edited_dict[word] += ['hero']\n",
    "    else:\n",
    "        edited_dict[word] = ['hero']\n",
    "\n",
    "edited_values = [['funct'], ['pronoun'], ['ppron'], ['i'], ['we'], ['you'], ['shehe'], ['they'], ['ipron'], ['article'], ['verb'], ['auxverb'], ['past'], ['present'], ['future'], ['adverb'], ['preps'], ['conj'], ['negate'], ['quant'], ['number'], ['swear'], ['social'], ['family'], ['friend'], ['humans'], ['affect'], ['posemo'], ['negemo'], ['anx'], ['anger'], ['sad'], ['cogmech'], ['insight'], ['cause'], ['discrep'], ['tentat'], ['certain'], ['inhib'], ['incl'], ['excl'], ['percept'], ['see'], ['hear'], ['feel'], ['bio'], ['body'], ['health'], ['sexual'], ['ingest'], ['relativ'], ['motion'], ['space'], ['time'], ['work'], ['achieve'], ['leisure'], ['home'], ['money'], ['relig'], ['death'], ['assent'], ['nonfl'], ['filler'],\n",
    "['power'], ['royalty'], ['hero']]\n",
    "helper_odict = collections.OrderedDict()\n",
    "for i in range(len(edited_values)):\n",
    "    helper_odict[i] = edited_values[i]\n",
    "\n",
    "mydict = (edited_dict, helper_odict.values())\n",
    "# animals: horse, bird, dragon, beast, witch, fish, tortoise, lion, puma, snake, rabbit, mouse, hare, stag, serpent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c4954e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_liwc = pd.DataFrame()\n",
    "for i in stories.index:\n",
    "    text = stories['text'][i]\n",
    "    liwc_counts = utils.wordCount(text, mydict)\n",
    "    liwc_df = pd.DataFrame(list(liwc_counts[0].items())).set_index(0) / liwc_counts[2]\n",
    "    liwc_df.columns = [stories.loc[i,'sid']]\n",
    "    stories_liwc = pd.concat([stories_liwc,liwc_df],axis=1)\n",
    "stories_liwc = stories_liwc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2bed07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nation_liwc = pd.merge(stories_hofstede,stories_liwc,right_index=True,left_on='sid').set_index('sid')\n",
    "nation_liwc = nation_liwc.groupby('nation').mean().reset_index()\n",
    "nation_liwc.columns\n",
    "hofstede_cols = ['pdi','idv','mas','uai','ltowvs','ivr']\n",
    "liwc_cols = nation_liwc.columns[8:]\n",
    "for col in liwc_cols:\n",
    "    nation_liwc[col] = (nation_liwc[col] - nation_liwc[col].mean())/nation_liwc[col].std()\n",
    "\n",
    "nation_liwc.to_csv(save_progress+\"nation_liwc.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69b559d",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "731b7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_corpus = [models.doc2vec.TaggedDocument(words=l, tags=[str(i)]) for i, l in enumerate(lemmas)]\n",
    "# doc_model = models.doc2vec.Doc2Vec(doc_corpus, min_count=200, window=10, workers=8)\n",
    "# doc_model.save(save_progress+'doc2vec.model')\n",
    "# doc_model = models.doc2vec.Doc2Vec.load(save_progress+'doc2vec.model')\n",
    "# tsne = utils.doc2vec_tsne(doc_model, stories['language_family'])\n",
    "tsne = pd.merge(tsne, stories[['nation','language_family']], left_index=True, right_index=True, how='left')\n",
    "tsne = tsne.rename(columns={'nation':'Nation'})\n",
    "tsne['Nation'] = tsne['Nation'].str.title()\n",
    "tsne['language_family'] = tsne['language_family'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2c095b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.to_csv(save_progress+\"tsne.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "951516fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Nation</th>\n",
       "      <th>language_family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17.040495</td>\n",
       "      <td>6.338946</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>East_Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.613154</td>\n",
       "      <td>23.311752</td>\n",
       "      <td>Serbian</td>\n",
       "      <td>Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.550614</td>\n",
       "      <td>-11.772786</td>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.067266</td>\n",
       "      <td>30.262329</td>\n",
       "      <td>French</td>\n",
       "      <td>Italic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.574621</td>\n",
       "      <td>33.876457</td>\n",
       "      <td>North_American_Native</td>\n",
       "      <td>Native_American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>-13.959932</td>\n",
       "      <td>22.061859</td>\n",
       "      <td>Australian_Ethnic</td>\n",
       "      <td>Austronesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>4.039639</td>\n",
       "      <td>13.369742</td>\n",
       "      <td>Scottish</td>\n",
       "      <td>Celtic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>-17.184561</td>\n",
       "      <td>-11.282936</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Italic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>5.765532</td>\n",
       "      <td>-33.906895</td>\n",
       "      <td>Norwegian</td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>5.417030</td>\n",
       "      <td>4.717605</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>Uralic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1         X2                 Nation  language_family\n",
       "0    -17.040495   6.338946               Japanese        East_Asia\n",
       "1     -1.613154  23.311752                Serbian           Slavic\n",
       "2     -7.550614 -11.772786                 German         Germanic\n",
       "3     28.067266  30.262329                 French           Italic\n",
       "4    -18.574621  33.876457  North_American_Native  Native_American\n",
       "...         ...        ...                    ...              ...\n",
       "2927 -13.959932  22.061859      Australian_Ethnic     Austronesian\n",
       "2928   4.039639  13.369742               Scottish           Celtic\n",
       "2929 -17.184561 -11.282936                Italian           Italic\n",
       "2930   5.765532 -33.906895              Norwegian         Germanic\n",
       "2931   5.417030   4.717605                Finnish           Uralic\n",
       "\n",
       "[2932 rows x 4 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6535b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca20 = utils.doc2vec_tsne(doc_model, stories['language_family'], 20)\n",
    "pca20 = pd.merge(pca20, stories[['nation','language_family']], left_index=True, right_index=True, how='left')\n",
    "pca20 = pca20.rename(columns={'nation':'Nation'})\n",
    "pca20['Nation'] = pca20['Nation'].str.title()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1ade0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vals = utils.doc2vec_tsne(doc_model, stories['language_family'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b661b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-17.040495 ,   6.3389463],\n",
       "       [ -1.613154 ,  23.311752 ],\n",
       "       [ -7.5506144, -11.772786 ],\n",
       "       ...,\n",
       "       [-17.18456  , -11.282936 ],\n",
       "       [  5.7655325, -33.906895 ],\n",
       "       [  5.4170303,   4.7176046]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f996109",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceddd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(lemmas.sample(frac=0.5))\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in lemmas]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "920ab7bd2fb7bd74b8de78632b6a92fbd66bc8d5dac803b94bc0f9d7f61a3b48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
